{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "ee046211_hw3_300427259.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## HW3 - Sequential Tasks and Training Methods\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq2c8X93pGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/clouds/96/000000/keyboard.png\" style=\"height:50px;display:inline\"> Keyboard Shortcuts\n",
        "---\n",
        "* Run current cell: **Ctrl + Enter**\n",
        "* Run current cell and move to the next: **Shift + Enter**\n",
        "* Show lines in a code cell: **Esc + L**\n",
        "* View function documentation: **Shift + Tab** inside the parenthesis or `help(name_of_module)`\n",
        "* New cell below: **Esc + B**\n",
        "* Delete cell: **Esc + D, D** (two D's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "* Fill in\n",
        "\n",
        "|Name     |Campus Email| ID  |\n",
        "|---------|--------------------------------|----------|\n",
        "|Roy Elkabetz| roy-e@campus.technion.ac.il| 300427259|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDK5zqhdpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/upload-to-cloud.png\" style=\"height:50px;display:inline\"> Submission Guidelines\n",
        "---\n",
        "* Maximal garde: 100.\n",
        "* Submission only in **pairs**. \n",
        "    * Please make sure you have registered your group in Moodle (there is a group creation component on the Moodle where you need to create your group and assign members).\n",
        "* **No handwritten submissions.** You can choose whether to answer in a Markdown cell in this notebook or attach a PDF with your answers.\n",
        "* <a style='color:red'> SAVE THE NOTEBOOKS WITH THE OUTPUT, CODE CELLS THAT WERE NOT RUN WILL NOT GET ANY POINTS! </a>\n",
        "* What you have to submit:\n",
        "    * If you have answered the questions in the notebook, you should submit this file only, with the name: `ee046211_hw3_id1_id2.ipynb`.\n",
        "    * If you answered the questionss in a different file you should submit a `.zip` file with the name `ee046211_hw3_id1_id2.zip` with content:\n",
        "        * `ee046211_hw3_id1_id2.ipynb` - the code tasks\n",
        "        * `ee046211_hw3_id1_id2.pdf` - answers to questions.\n",
        "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
        "* Submission on the course website (Moodle).\n",
        "* **Latex in Colab** - in some cases, Latex equations may no be rendered. To avoid this, make sure to not use *bullets* in your answers (\"* some text here with Latex equations\" -> \"some text here with Latex equations\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSj_UufpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/online.png\" style=\"height:50px;display:inline\"> Working Online and Locally\n",
        "---\n",
        "* You can choose your working environment:\n",
        "    1. `Jupyter Notebook`, **locally** with <a href=\"https://www.anaconda.com/distribution/\">Anaconda</a> or **online** on <a href=\"https://colab.research.google.com/\">Google Colab</a>\n",
        "        * Colab also supports running code on GPU, so if you don't have one, Colab is the way to go. To enable GPU on Colab, in the menu: `Runtime`$\\rightarrow$ `Change Runtime Type` $\\rightarrow$`GPU`.\n",
        "    2. Python IDE such as <a href=\"https://www.jetbrains.com/pycharm/\">PyCharm</a> or <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>.\n",
        "        * Both allow editing and running Jupyter Notebooks.\n",
        "\n",
        "* Please refer to `Setting Up the Working Environment.pdf` on the Moodle or our GitHub (https://github.com/taldatech/ee046211-deep-learning) to help you get everything installed.\n",
        "* If you need any technical assistance, please go to our Piazza forum (`hw3` folder) and describe your problem (preferably with images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp1Fp4ppGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "\n",
        "* [Part 1 - Theory](#-Part-1---Theory)\n",
        "    * [Q1 - Deep NLP Case Study](#-Question-1--Deep-NLP-Case-Study)\n",
        "    * [Q2 -Layer Normalization](#-Question-2--Layer-Normalization)\n",
        "    * [Q3 - Batch Normalization](#-Question-3--Batch-Normalization)\n",
        "* [Part 2 - Code Assignments - Sequence-to-Sequence with Transformers](#-Part-2---Code-Assignments)\n",
        "    * [Task 1 - Task 1 - Loading and Observing the Data](#-Task-1----Loading-and-Observing-the-Data)\n",
        "    * [Task 2 - Preparing the Data - Separating to Inputs and Targets](#-Task-2----Preparing-the--Data---Separating-to-Inputs-and-Targets)\n",
        "    * [Task 3 - Define Hyperparameters and Initialize the Model](#-Task-3----Define-Hyperparameters-and-Initialize-the-Model)\n",
        "    * [Task 4 - Train and Evaluate the Language Model](#-Task-4----Train-and-Evaluate-the-Language-Model)\n",
        "    * [Task 5 - Generate Sentences](#-Task-5----Generate-Sentences)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtSiQX_pGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cute-clipart/64/000000/ball-point-pen.png\" style=\"height:50px;display:inline\"> Part 1 - Theory\n",
        "---\n",
        "* You can choose whether to answser these straight in the notebook (Markdown + Latex) or use another editor (Word, LyX, Latex, Overleaf...) and submit an additional PDF file, **but no handwritten submissions**.\n",
        "* You can attach additional figures (drawings, graphs,...) in a separate PDF file, just make sure to refer to them in your answers.\n",
        "\n",
        "* $\\large\\LaTeX$ <a href=\"https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index\">Cheat-Sheet</a> (to write equations)\n",
        "    * <a href=\"http://tug.ctan.org/info/latex-refsheet/LaTeX_RefSheet.pdf\">Another Cheat-Sheet</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsqSFZG1pGhj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 1 -Deep NLP Case Study\n",
        "---\n",
        "* You are consulting for a healthcare company. They provide you with clinical notes of the first encounter that each patient had with their doctor regarding a particular medical episode.\n",
        "* There are a total of 12 million patients and clinical notes. At the time that each clinical note was written, the underlying illnesses associated with the medical episode were unknown to the doctor. \n",
        "* The company provides you with the true set of illnesses associated with each medical episode and asks you to build a model that can infer these underlying illnesses using only the current clinical note and all previous clinical notes belonging to the patient.\n",
        "* The set of notes provided to you span 10 years; each patient therefore can have multiple clinical notes (medical episodes) in that period.\n",
        "* You also have a vector representation of each patient note (note-vector) which was built using a summation of the word vectors of the note.\n",
        "\n",
        "\n",
        "1. You assume that a patient’s past medical history is informative of their current illness. As such, you apply a recurrent neural network to predict the current illness based on the patient’s current and previous note-vectors. Explain why a recurrent neural network would yield better results than a feed-forward network in which your input is the summation of past and current note-vectors?\n",
        "\n",
        "2. A patient may have any number of illnesses from a list of 70,000 known medical illnesses. The output of your recurrent neural network will therefore be a vector with 70,000 elements. Each element in this output vector represents the probability that the patient has the illness that maps to that particular element. Illnesses are not mutually exclusive i.e. having one illness does not preclude you from having any other illnesses. Given this insight, is it better to have a sigmoid non-linearity or a softmax non-linearity as your output unit? Why?\n",
        "\n",
        "3. You try to figure out a better way to reduce the training and testing time of your model. You perform a run time analysis and observe that the computational bottleneck is in your output unit: the number of target illnesses is too high. Each illness in the list of 70,000 illnesses belongs to one of 300 classes (e.g. a migraine belongs to the neurological disorder class). He shares with you a dictionary which maps each illness to its corresponding class. How can you use this information to reduce the **time** complexity of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkNkld8qSs-S"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 1 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "\n",
        "1. Using a feed-forward network for that task would be to totaly ignore any time / sequential information about the patient's medical data which also would lead to disregarding any cause and effect between following events. Using an RNN would solve that problem by acquiring the sequential information from the order at which the vector notes are fed into the network.\n",
        "\n",
        "2. Because illnesses are not mutually exclusive, the probability of a paitient to have one illness could be (in general) independent of some other illnesses which can also accure. Using a softmax activation on the last layer would give us a probability distribution over the output vector (illnesses) such that the probability of having some illness would be on the expense of the other (which in general wouldn't be the case). For example, a paitent could torn his acl and have diarrhea at the same time without of this two ilnesses be conected in any way. Therefore, it would be better to use a sigmoid activation over the output layer which results in a mapping of any output unit into $[0, 1]$ which can be interpreted as the probability of he patient to have that specific illness.\n",
        "\n",
        "3. In order to reduce the time complexity of the model we can use the $300$ classes list as the output of the model with a sigmoid activation over each unit in the $300$ output vector. Thus, the model would (given the same input) output the probabilities of the patient to have an illness in one or more of the classes in the $300$ classes list. Then, defining some threshold for the probability of having an illness in some class we can then classify between the illnesses only for the classes who got a probability above that treshold.\n",
        "Althogh in this method we add another classifer ontop of the previouse model (which is time consuming) we also reduce the size of the model's output dramatically to $300$ from $70000$ units. Then, given some interesting classes with high probability we now look in a much smaller subspace of illnesses which on average would be of the size of $70000/300 \\approx 230$ classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD06dr7FSs-S"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 2 -Layer Normalization\n",
        "---\n",
        "\n",
        "1. When does Group Normalization is equivalent to Instance Normalization?\n",
        "2. When does Group Normalization is equivalent to Layer Normalization?\n",
        "3. For the following batch of $N=3$ 2D images with $C=3$ channels each, what is the output of:\n",
        "    * Batch Normalization\n",
        "    * Layer Normalization\n",
        "    * Instance Normalization\n",
        "\n",
        "\n",
        "* Use only the *mean* for the calculation, no need for the std (assume there are no learnable parameters).\n",
        "    \n",
        "$$ n=1: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "426vA9fpSs-T"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 2 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "\n",
        "\n",
        "1. Instance Normalization means normalizing over the width and height dimensions while Group Normalization means normalizing over the width, height and some of the channels dimensions. Therefore, Group Normalization and Instance Normalization are equivalent when each group consists of a single channel.\n",
        "\n",
        "2. Layer Normalization means normalizing over the width, height and all channels of a specific layer. Therefore Group normalization and Layer normalization are equivalent when a group in a group normalization consists of all the channels in a specific layer.\n",
        "\n",
        "3. \n",
        " - **Batch Normalization:**\n",
        " \\begin{align}\n",
        "     C_1&: \\quad\\frac{2*1 + 4*0.5 + 3*1 + 1*0.5}{12}=\\frac{7.5}{12}=0.625\\\\\n",
        "     C_2&: \\quad\\frac{2*1 + 2*0.5 + 2*1 + 2*0.5}{12}=\\frac{6}{12}=0.5\\\\\n",
        "     C_3&: \\quad\\frac{4*1 + 2*0.5 + 3*1 + 1*0.5}{12}=\\frac{8.5}{12}=0.708\n",
        " \\end{align}\n",
        " \n",
        " Then, the output would be\n",
        " \\begin{align}\n",
        "     n=1&: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}-0.625, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}-0.5, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}-0.708\\\\\n",
        "     n=2&: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}-0.625, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}-0.5, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix}-0.708\\\\\n",
        "     n=3&: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}-0.625, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}-0.5, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix}-0.708\n",
        " \\end{align}\n",
        " \n",
        " Therefore,\n",
        " \\begin{align}\n",
        "     n=1&: \\begin{bmatrix} -0.625 & 0.375 \\\\ 0.375 & -0.625 \\end{bmatrix}, \\begin{bmatrix} 0.5 & -0.5 \\\\ -0.5 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.292 & 0.292 \\\\ 0.292 & 0.292 \\end{bmatrix}\\\\\n",
        "     n=2&: \\begin{bmatrix} -0.125 & -0.125 \\\\ -0.125 & -0.125 \\end{bmatrix}, \\begin{bmatrix} 0 & -0.5 \\\\ 0 & -0.5 \\end{bmatrix}, \\begin{bmatrix} -0.708 & -0.208 \\\\ -0.708 & -0.208 \\end{bmatrix}\\\\\n",
        "     n=3&: \\begin{bmatrix} 0.375 & 0.375 \\\\ 0.375 & -0.125 \\end{bmatrix}, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.292 & -0.208 \\\\ 0.292 & 0.292 \\end{bmatrix}\n",
        " \\end{align}\n",
        " \n",
        " - **Layer Normalization**\n",
        " \\begin{align}\n",
        "     n_1&: \\quad\\frac{2*1 + 2*1 + 4*1}{12}=\\frac{8}{12}=0.667\\\\\n",
        "     n_2&: \\quad\\frac{4*0.5 + 2*0.5 + 2*0.5}{12}=\\frac{4}{12}=0.333\\\\\n",
        "     n_3&: \\quad\\frac{3*1 + 1*0.5 + 2*1 + 2*0.5 + 3*1 + 1*0.5}{12}=\\frac{10}{12}=0.833\n",
        " \\end{align}\n",
        " \n",
        " Then, the output would be\n",
        " \\begin{align}\n",
        "     n=1&: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}-0.667, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}-0.667, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}-0.667\\\\\n",
        "     n=2&: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}-0.333, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}-0.333, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix}-0.333\\\\\n",
        "     n=3&: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}-0.833, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}-0.833, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix}-0.833\n",
        " \\end{align}\n",
        " \n",
        " Therefore,\n",
        " \\begin{align}\n",
        "     n=1&: \\begin{bmatrix} -0.667 & 0.333 \\\\ 0.333 & -0.667 \\end{bmatrix}, \\begin{bmatrix} 0.333 & -0.667 \\\\ -0.667 & 0.333 \\end{bmatrix}, \\begin{bmatrix} 0.333 & 0.333 \\\\ 0.333 & 0.333 \\end{bmatrix}\\\\\n",
        "     n=2&: \\begin{bmatrix} 0.167 & 0.167 \\\\ 0.167 & 0.167 \\end{bmatrix}, \\begin{bmatrix} 0.167 & -0.333 \\\\ 0.167 & -0.333 \\end{bmatrix}, \\begin{bmatrix} -0.333 & 0.167 \\\\ -0.333 & 0.167 \\end{bmatrix}\\\\\n",
        "     n=3&: \\begin{bmatrix} 0.167 & 0.167 \\\\ 0.167 & -0.333 \\end{bmatrix}, \\begin{bmatrix} -0.333 & 0.167 \\\\ -0.333 & 0.167 \\end{bmatrix}, \\begin{bmatrix} 0.167 & -0.333 \\\\ 0.167 & 0.167 \\end{bmatrix}\n",
        " \\end{align}\n",
        " \n",
        "  - **Instance Normalization**\n",
        "  \\begin{align}\n",
        "     n_1, C_1&: \\quad\\frac{2*1}{4}=0.5\\\\\n",
        "     n_1, C_2&: \\quad\\frac{2*1}{4}=0.5\\\\\n",
        "     n_1, C_3&: \\quad\\frac{4*1}{4}=1\\\\\n",
        "     n_2, C_1&: \\quad\\frac{4*0.5}{4}=0.5\\\\\n",
        "     n_2, C_2&: \\quad\\frac{2*0.5}{4}=0.25\\\\\n",
        "     n_2, C_3&: \\quad\\frac{2*0.5}{4}=0.25\\\\\n",
        "     n_3, C_1&: \\quad\\frac{3*1 + 1*0.5}{4}=0.875\\\\\n",
        "     n_3, C_2&: \\quad\\frac{2*1 + 2*0.5}{4}=0.75\\\\\n",
        "     n_3, C_3&: \\quad\\frac{3*1 + 1*0.5}{4}=0.875\n",
        " \\end{align}\n",
        " \n",
        " Then, the output would be\n",
        " \\begin{align}\n",
        "     n=1&: \n",
        "     \\begin{bmatrix} -0.5 & 0.5 \\\\ 0.5 & -0.5 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} 0.5 & -0.5 \\\\ -0.5 & 0.5 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}\\\\\n",
        "     n=2&: \n",
        "     \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} 0.25 & -0.25 \\\\ 0.25 & -0.25 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} -0.25 & 0.25 \\\\ -0.25 & 0.25 \\end{bmatrix}\\\\\n",
        "     n=3&: \n",
        "     \\begin{bmatrix} 0.125 & 0.125 \\\\ 0.125 & -0.375 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} -0.25 & 0.25 \\\\ -0.25 & 0.25 \\end{bmatrix}, \n",
        "     \\begin{bmatrix} 0.125 & -0.375 \\\\ 0.125 & 0.125 \\end{bmatrix}\n",
        " \\end{align}\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEhXAhNASs-V"
      },
      "source": [
        "# imports for the practice (you can add more if you need)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQEo5gMeSs-a",
        "outputId": "761f4683-c486-408d-bb5e-faa3acfc7bca"
      },
      "source": [
        "# verifying Question 2.3 hand computation with code\n",
        "x1 = np.array([[[0, 1], [1., 0]], [[1, 0], [0, 1]], [[1, 1], [1, 1]]], dtype=np.float)\n",
        "x2 = np.array([[[0.5, 0.5], [0.5, 0.5]], [[0.5, 0], [0.5, 0]], [[0, 0.5], [0, 0.5]]], dtype=np.float)\n",
        "x3 = np.array([[[1, 1], [1, 0.5]], [[0.5, 1], [0.5, 1]], [[1, 0.5], [1, 1]]], dtype=np.float)\n",
        "x = torch.from_numpy(np.array([x1, x2, x3])).float()\n",
        "y = x.transpose(1, 0)\n",
        "batch = nn.BatchNorm2d(3, affine=False, momentum=1)\n",
        "batch_out = batch(x)\n",
        "print(f'The BatchNorm2D values for all channels, C1, C2, C3 are {batch.running_mean}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BatchNorm2D values for all channels, C1, C2, C3 are tensor([0.6250, 0.5000, 0.7083])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MefRg8cPSs-c"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 3 -Batch Normalization\n",
        "---\n",
        "This question relates to lectures 8-9 (from slide 9):\n",
        "\n",
        "Prove that **without** regularization, BatchNorm **scale invariance** for parameters $\\mathbf{w}$ implies:\n",
        "1. $\\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w} = 0$\n",
        "2. And under gradient flow dynamics ($\\dot{\\mathbf{w}} = -\\eta \\nabla \\mathcal{L}(\\mathbf{w})$) this implies (L2) norm conservation: $\\forall t: ||\\mathbf{w}(t)||^2 = C$\n",
        "\n",
        "Hint: see results from the multilayer networks lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-14iM7pGhm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/officel/80/000000/code.png\" style=\"height:50px;display:inline\"> Part 2 - Code Assignments\n",
        "---\n",
        "* You must write your code in this notebook and save it with the output of all of the code cells.\n",
        "* Additional text can be added in Markdown cells.\n",
        "* You can use any other IDE you like (PyCharm, VSCode...) to write/debug your code, but for the submission you must copy it to this notebook, run the code and save the notebook with the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPCh65i1mAqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022577dd-d4e6-4f16-d3f0-46cc32d7b215"
      },
      "source": [
        "# Get Telegram alert to phone when training finishes\n",
        "!pip install python-telegram-bot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.6)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2020.12.5)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (6.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8-Im9sGmHWm",
        "outputId": "be2d3257-4040-4f6c-9e45-6c8712a8b391"
      },
      "source": [
        "# mount drive for bot id and tokens\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import json\n",
        "import telegram\n",
        "\n",
        "def send_message(message):\n",
        "    \"This function sends a message to telegram acount\"\n",
        "    with open('/content/gdrive/MyDrive/telegram_bot_key.txt', 'r') as keys_file:\n",
        "        k = json.load(keys_file)\n",
        "        token = k['telegram_token']\n",
        "        chat_id = k['telegram_chat_id']\n",
        "    bot = telegram.Bot(token=token)\n",
        "    bot.sendMessage(chat_id=chat_id, text=message)\n",
        "\n",
        "send_message('Telegram pinger is connected.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccAc_TowfrD",
        "outputId": "f321bc09-521e-487f-93b9-2a7f09cdc0e2"
      },
      "source": [
        "pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 12.5MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.15)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 24.6MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/06/ea782764035efa0633b6353202f3f86b7c390fe11d4dfd33af9b49344130/cmd2-2.0.1-py3-none-any.whl (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 23.9MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 26.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=5b85ffb632831feb3255ce7840b6d13715fa6229bfb0f7e0ba31255884140225\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pbr, stevedore, colorama, pyperclip, cmd2, cliff, Mako, python-editor, alembic, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.0.1 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL_itYmqSs-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0df357-88bc-4053-eb22-4dcd229310e3"
      },
      "source": [
        "# imports for the practice (you can add more if you need)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from tqdm.autonotebook import tqdm\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import torchtext.legacy.data as data\n",
        "import torchtext.legacy.datasets as datasets\n",
        "import torch.nn.functional as f\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "# optuna\n",
        "import optuna\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "print(f'torch {torch.__version__}')\n",
        "print('Device properties:')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    gpu_data = torch.cuda.get_device_properties(0)\n",
        "    gpu_name = gpu_data.name\n",
        "    gpu_mem  = f'{gpu_data.total_memory * 1e-9:.02f} Gb'\n",
        "    print(f'GPU: {gpu_name}\\nMemory: {gpu_mem}')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch 1.8.1+cu101\n",
            "Device properties:\n",
            "GPU: Tesla K80\n",
            "Memory: 12.00 Gb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVJJPJLSs-d"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/workflow.png\" style=\"height:50px;display:inline\">  Sequence-to-Sequence with Transformers\n",
        "---\n",
        "* In this exercise, you are going to build a language model using PyTroch's Transformer module.\n",
        "* We will work with the **Wikitext-2** dataset: the WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.\n",
        "* After training, you will be able to generate senetences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGa6HDzdSs-d"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 1  - Loading and Observing the Data\n",
        "---\n",
        "1. Initialize a text `data.Field` using `data.utils.get_tokenizer(\"basic_english\")`, `<sos>` and `<eos>` as start and end tokens, and consider only lower case words (`lower=True`).\n",
        "2. Load the train, valid and test *texts* using `datasets.WikiText2.splits` with your text data field from (1).\n",
        "3. Build a vocabulary using only the train data.\n",
        "4. Create the train, valid and test data using the provided `batchify` function.\n",
        "5. Use the `batchify` function with `batch_size=20` to create a data loader. Print the shape of the result.\n",
        "6. Print 2 train samples. Use the vocabulary you built to transfer between tokens to words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEoSv8-wSs-d"
      },
      "source": [
        "def batchify(data, bsz, text_field):\n",
        "    data = text_field.numericalize([data.examples[0].text])\n",
        "    # Divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "EVdQGasD_tEg",
        "outputId": "96268fb4-3ac9-4efb-8001-3a61933022eb"
      },
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "# get tokenizer\n",
        "tokenizer = data.utils.get_tokenizer(\"basic_english\")\n",
        "\n",
        "# define the text field for the dataset\n",
        "text = data.Field(sequential=True,\n",
        "                  lower=True, \n",
        "                  tokenize=tokenizer,\n",
        "                  init_token='<sos>', \n",
        "                  eos_token='<eos>',\n",
        "                  dtype=torch.long)\n",
        "\n",
        "# download the WikiText2 dataset\n",
        "train_Wiki2, val_Wiki2, test_Wiki2 = datasets.WikiText2.splits(text_field=text)\n",
        "\n",
        "# create vocabulary\n",
        "text.build_vocab(train_Wiki2)\n",
        "vocab = text.vocab\n",
        "\n",
        "# split the data into batches\n",
        "batch_size = 20\n",
        "train_loader = batchify(train_Wiki2, batch_size, text)\n",
        "val_loader = batchify(val_Wiki2, batch_size, text)\n",
        "test_loader = batchify(test_Wiki2, batch_size, text)\n",
        "display(HTML('<h4>Data loaders shapes:</h4>'))\n",
        "print(f'The train dataset shape is: {train_loader.shape}')\n",
        "print(f'The validation dataset shape is: {val_loader.shape}')\n",
        "print(f'The test dataset shape is: {test_loader.shape}')\n",
        "\n",
        "# display data samples\n",
        "display(HTML('<h4>Display data samples:</h4>'))\n",
        "n_samples = 2\n",
        "for i in range(n_samples):\n",
        "    tokens = train_loader[i]\n",
        "    print(f'Sample {i}:')\n",
        "    print(f'Tokens: {list(tokens.cpu().numpy())}')\n",
        "    print(\"Text: \", \" \".join([vocab.itos[t] for t in tokens]))\n",
        "    print('\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading wikitext-2-v1.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "wikitext-2-v1.zip: 100%|██████████| 4.48M/4.48M [00:00<00:00, 6.72MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>Data loaders shapes:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The train dataset shape is: torch.Size([104335, 20])\n",
            "The validation dataset shape is: torch.Size([10908, 20])\n",
            "The test dataset shape is: torch.Size([12310, 20])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>Display data samples:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Sample 0:\n",
            "Tokens: [3, 25, 1849, 570, 7, 5, 5, 9258, 4, 56, 0, 7, 6, 6634, 4, 6603, 6, 5, 65, 30]\n",
            "Text:  <eos> @ settlement heavy of , , lined the she <unk> of . interception the dried . , would his\n",
            "\n",
            "\n",
            "Sample 1:\n",
            "Tokens: [12, 66, 13, 4889, 458, 8, 1045, 21, 19094, 34, 147, 4, 0, 10, 2280, 2294, 58, 35, 2438, 4064]\n",
            "Text:  = 1 was rains ireland and starting with hairy had found the <unk> to possibility heads other which receive gift\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRfhYBV6Ss-e"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 2  - Preparing the  Data - Separating to Inputs and Targets\n",
        "---\n",
        "* For a language modeling task, the model needs the following words as `Target`.\n",
        "    * For example, for the senetence \"I have a nice dog\", the model will be given \"I have a\" as input, and \"nice dog\" as the target.\n",
        "* Implement (complete) the function `get_batch(source, i, bptt)`: it generates the input and target sequence for the transformer model. It subdivides the source data into chunks of length `bptt`.\n",
        "    * For example, for `bptt=2` and at `i=0`, the output of `data, target = get_batch(train_data, i=0, bptt=2)`: `data` will be of shape (2, 20), where the batch size is 20 and `target` will be of length 40 (the target for each element is two words, but we flatten `target`).\n",
        "    * Print a sample from `data` and `target`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fwmJAO6Ss-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b91b987-4eba-4e00-f776-1c7e5dc58303"
      },
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def get_batch(source, i, bptt):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i + seq_len]\n",
        "    target = source[i + 1:i + 1 + seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "data, target = get_batch(train_loader, i=0, bptt=2)\n",
        "print(f'The data shape {data.cpu().numpy().shape}, The target shape {target.cpu().numpy().shape}\\n')\n",
        "print(f\"Data:\\n {data.cpu().numpy()}\\n\")\n",
        "print(f\"Target:\\n {target.cpu().numpy()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data shape (2, 20), The target shape (40,)\n",
            "\n",
            "Data:\n",
            " [[    3    25  1849   570     7     5     5  9258     4    56     0     7\n",
            "      6  6634     4  6603     6     5    65    30]\n",
            " [   12    66    13  4889   458     8  1045    21 19094    34   147     4\n",
            "      0    10  2280  2294    58    35  2438  4064]]\n",
            "\n",
            "Target:\n",
            " [   12    66    13  4889   458     8  1045    21 19094    34   147     4\n",
            "     0    10  2280  2294    58    35  2438  4064  3852 13667  2962    68\n",
            "     6 28374    39   417     0  2034    29    88 27804   350     7    17\n",
            "  4811   902    33    20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "760tslmbSs-e"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 3  - Define Hyperparameters and Initialize the Model\n",
        "---\n",
        "* Define the following hyperparameters (`[a, b]` means in the range between `a` and `b`):\n",
        "    * Embedding size: choose from `[200, 250]`\n",
        "    * Number of hidden units: choose from `[200, 250]`\n",
        "    * Number of layers: choose from `[2, 4]`\n",
        "    * Number of attention heads: choose from `[2, 4]`\n",
        "    * Dropout: choose from `[0.0, 0.3]`\n",
        "    * Loss criterion: `nn.CrossEntropyLoss()`\n",
        "    * Optimizer: choose from `[SGD, Adam]`\n",
        "    * Learning rate: choose from `[5e-3, 5.0]`\n",
        "    * Learning Scheduler: `torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)`\n",
        "* Intialize an instance of `TransformerModel` (given) and send it to `device`. Note that you need to give it the number of tokens to define the output of the decoder. You should use the number of tokens in the vocabulary. Print the number of tokens,  print **all** the chosen hyper-parameters and print the model (`print(model`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S441OcJBSs-e"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsdV-MQSs-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b89f067-b589-424c-a249-beb35e67e293"
      },
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "\n",
        "## The best Optuna results from the fine optimization process \n",
        "## at the buttom of the notebook.\n",
        "\"\"\"\n",
        "Study statistics: \n",
        "  Number of finished trials:  40\n",
        "  Number of pruned trials:  24\n",
        "  Number of complete trials:  16\n",
        "Best trial:\n",
        "  Value:  4.999077273145259\n",
        "  Params: \n",
        "    emsize: 240\n",
        "    lr: 2.9532273669338855\n",
        "    nlayers: 3\n",
        "    nhid: 214\n",
        "    nhead: 2\n",
        "    dropout: 0.0679924404226665\n",
        "    step_decay: 3\n",
        "    gamma: 0.11387398408524015\n",
        "\"\"\"\n",
        "\n",
        "# Hyperparameters\n",
        "emsize = 240              # embbeding size\n",
        "ntokens = len(vocab.stoi) # the size of vocabulary\n",
        "lr = 2.95                  # learning rate\n",
        "nlayers = 3               # number of layers\n",
        "nhid = 214                # number of hidden units\n",
        "nhead = 2                 # number of Attention heads\n",
        "dropout = 0.068             # dropout probability\n",
        "step_decay = 4          # Period of learning rate decay\n",
        "gamma = 0.514              # decay value for learning rate\n",
        "\n",
        "display(HTML('<h4>The Model Hyperparameters:</h4>'))\n",
        "print(f'Number of tokens in the vocabulary: {ntokens}')\n",
        "print(f'Embedding size: {emsize}')\n",
        "print(f'Number of Attention heads: {nhead}')\n",
        "print(f'Number of hidden uints: {nhid}')\n",
        "print(f'Number of layers: {nlayers}')\n",
        "print(f'Dropout: {dropout}')\n",
        "print(f'Step decay for learning rate: {step_decay}')\n",
        "print(f'Learning rate: {lr}')\n",
        "print(f'Decay value for learning rate: {gamma}')\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_decay, gamma=gamma)\n",
        "\n",
        "display(HTML('<h4>The Model:</h4>'))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>The Model Hyperparameters:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of tokens in the vocabulary: 28785\n",
            "Embedding size: 240\n",
            "Number of Attention heads: 2\n",
            "Number of hidden uints: 214\n",
            "Number of layers: 3\n",
            "Dropout: 0.068\n",
            "Step decay for learning rate: 4\n",
            "Learning rate: 2.95\n",
            "Decay value for learning rate: 0.514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>The Model:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TransformerModel(\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.068, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=214, bias=True)\n",
            "        (dropout): Dropout(p=0.068, inplace=False)\n",
            "        (linear2): Linear(in_features=214, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.068, inplace=False)\n",
            "        (dropout2): Dropout(p=0.068, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=214, bias=True)\n",
            "        (dropout): Dropout(p=0.068, inplace=False)\n",
            "        (linear2): Linear(in_features=214, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.068, inplace=False)\n",
            "        (dropout2): Dropout(p=0.068, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=214, bias=True)\n",
            "        (dropout): Dropout(p=0.068, inplace=False)\n",
            "        (linear2): Linear(in_features=214, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.068, inplace=False)\n",
            "        (dropout2): Dropout(p=0.068, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Embedding(28785, 240)\n",
            "  (decoder): Linear(in_features=240, out_features=28785, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afwPxELLSs-f"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 4  - Train and Evaluate the Language Model\n",
        "---\n",
        "* Fill in the missing line in the training code and train the model.\n",
        "* Use `bptt=35`.\n",
        "* Use the provided function to evaluate it on the validatation set (after each epoch) and on test test (after training is done). **Print and plot** the results (loss and perplexity).\n",
        "* If you see that the performance does not improve, go back to Task 3 and re-think you hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHvVYhc0Ss-f"
      },
      "source": [
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    ntokens = len(vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i, bptt)\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvW6NQFOSs-f"
      },
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def train(bptt, logger):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    epoch_total_loss = 0.\n",
        "    counter = 0\n",
        "    start_time = time.time()\n",
        "    ntokens =  len(vocab.stoi) #complete\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_loader.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_loader, i, bptt)\n",
        "        \n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            \n",
        "        output = model(data, src_mask) # complete\n",
        "        loss = criterion(output.view(-1, ntokens), targets) # complete\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            epoch_total_loss += cur_loss\n",
        "            counter += 1\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_loader) // bptt, scheduler.get_last_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "    logger['train_loss'].append(epoch_total_loss / counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm2OoFVV1I7q",
        "outputId": "9d653086-859b-49b0-a8d5-47e3d453ea3a"
      },
      "source": [
        "CHECKPOINT_DIR = '/content/gdrive/MyDrive/Checkpoints'\n",
        "MODEL_NAME = 'LM_Transformer'\n",
        "\n",
        "# create checkpoint directory to save model results\n",
        "if not os.path.isdir(CHECKPOINT_DIR):\n",
        "    os.mkdir(CHECKPOINT_DIR)\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs = 30\n",
        "best_model = None\n",
        "bptt=35\n",
        "logger = {'train_loss': [], \n",
        "          'val_loss': [], \n",
        "          'epochs': []}\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(bptt=bptt, logger=logger)\n",
        "    val_loss = evaluate(model, val_loader)\n",
        "    logger['val_loss'].append(val_loss)\n",
        "    logger['epochs'].append(epoch)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "        \n",
        "        # save the model\n",
        "        state = {\n",
        "            'model': best_model.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'val_loss': val_loss,\n",
        "            'bptt': bptt,\n",
        "            'ntokens': ntokens, \n",
        "            'emsize': emsize, \n",
        "            'nhead': nhead, \n",
        "            'nhid': nhid, \n",
        "            'nlayers': nlayers, \n",
        "            'dropout': dropout,\n",
        "            'logger': logger\n",
        "        }\n",
        "        torch.save(state, f'{CHECKPOINT_DIR}/{MODEL_NAME}_{epoch}.pth')\n",
        "        print('-' * 89)\n",
        "        print('| Model was saved |')\n",
        "        print('-' * 89)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# send a message to my phone when training is done\n",
        "send_message('The training process of the LM_transformer is done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   200/ 2981 batches | lr 2.95 | ms/batch 42.77 | loss  7.65 | ppl  2096.47\n",
            "| epoch   1 |   400/ 2981 batches | lr 2.95 | ms/batch 42.00 | loss  6.65 | ppl   776.40\n",
            "| epoch   1 |   600/ 2981 batches | lr 2.95 | ms/batch 41.99 | loss  6.26 | ppl   524.43\n",
            "| epoch   1 |   800/ 2981 batches | lr 2.95 | ms/batch 41.99 | loss  6.13 | ppl   459.63\n",
            "| epoch   1 |  1000/ 2981 batches | lr 2.95 | ms/batch 41.94 | loss  6.00 | ppl   402.89\n",
            "| epoch   1 |  1200/ 2981 batches | lr 2.95 | ms/batch 42.02 | loss  5.95 | ppl   382.11\n",
            "| epoch   1 |  1400/ 2981 batches | lr 2.95 | ms/batch 42.02 | loss  5.88 | ppl   358.23\n",
            "| epoch   1 |  1600/ 2981 batches | lr 2.95 | ms/batch 41.99 | loss  5.88 | ppl   359.09\n",
            "| epoch   1 |  1800/ 2981 batches | lr 2.95 | ms/batch 41.97 | loss  5.77 | ppl   320.49\n",
            "| epoch   1 |  2000/ 2981 batches | lr 2.95 | ms/batch 41.89 | loss  5.76 | ppl   316.01\n",
            "| epoch   1 |  2200/ 2981 batches | lr 2.95 | ms/batch 41.90 | loss  5.63 | ppl   277.48\n",
            "| epoch   1 |  2400/ 2981 batches | lr 2.95 | ms/batch 41.90 | loss  5.67 | ppl   290.94\n",
            "| epoch   1 |  2600/ 2981 batches | lr 2.95 | ms/batch 41.93 | loss  5.67 | ppl   289.27\n",
            "| epoch   1 |  2800/ 2981 batches | lr 2.95 | ms/batch 41.82 | loss  5.56 | ppl   260.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 129.25s | valid loss  5.52 | valid ppl   250.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2981 batches | lr 2.95 | ms/batch 42.07 | loss  5.54 | ppl   255.12\n",
            "| epoch   2 |   400/ 2981 batches | lr 2.95 | ms/batch 42.03 | loss  5.52 | ppl   250.29\n",
            "| epoch   2 |   600/ 2981 batches | lr 2.95 | ms/batch 41.86 | loss  5.31 | ppl   202.09\n",
            "| epoch   2 |   800/ 2981 batches | lr 2.95 | ms/batch 41.89 | loss  5.34 | ppl   209.14\n",
            "| epoch   2 |  1000/ 2981 batches | lr 2.95 | ms/batch 41.84 | loss  5.28 | ppl   196.88\n",
            "| epoch   2 |  1200/ 2981 batches | lr 2.95 | ms/batch 41.95 | loss  5.30 | ppl   201.16\n",
            "| epoch   2 |  1400/ 2981 batches | lr 2.95 | ms/batch 41.89 | loss  5.32 | ppl   203.40\n",
            "| epoch   2 |  1600/ 2981 batches | lr 2.95 | ms/batch 41.84 | loss  5.36 | ppl   212.46\n",
            "| epoch   2 |  1800/ 2981 batches | lr 2.95 | ms/batch 41.86 | loss  5.27 | ppl   193.55\n",
            "| epoch   2 |  2000/ 2981 batches | lr 2.95 | ms/batch 41.83 | loss  5.28 | ppl   196.37\n",
            "| epoch   2 |  2200/ 2981 batches | lr 2.95 | ms/batch 41.91 | loss  5.15 | ppl   172.59\n",
            "| epoch   2 |  2400/ 2981 batches | lr 2.95 | ms/batch 41.93 | loss  5.23 | ppl   186.61\n",
            "| epoch   2 |  2600/ 2981 batches | lr 2.95 | ms/batch 41.82 | loss  5.24 | ppl   188.56\n",
            "| epoch   2 |  2800/ 2981 batches | lr 2.95 | ms/batch 41.78 | loss  5.15 | ppl   173.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 128.89s | valid loss  5.31 | valid ppl   202.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2981 batches | lr 2.95 | ms/batch 42.09 | loss  5.18 | ppl   177.69\n",
            "| epoch   3 |   400/ 2981 batches | lr 2.95 | ms/batch 42.13 | loss  5.19 | ppl   179.81\n",
            "| epoch   3 |   600/ 2981 batches | lr 2.95 | ms/batch 41.94 | loss  4.96 | ppl   142.86\n",
            "| epoch   3 |   800/ 2981 batches | lr 2.95 | ms/batch 41.80 | loss  5.02 | ppl   151.22\n",
            "| epoch   3 |  1000/ 2981 batches | lr 2.95 | ms/batch 41.80 | loss  4.98 | ppl   145.25\n",
            "| epoch   3 |  1200/ 2981 batches | lr 2.95 | ms/batch 41.79 | loss  5.01 | ppl   149.30\n",
            "| epoch   3 |  1400/ 2981 batches | lr 2.95 | ms/batch 41.85 | loss  5.04 | ppl   154.70\n",
            "| epoch   3 |  1600/ 2981 batches | lr 2.95 | ms/batch 41.77 | loss  5.09 | ppl   162.82\n",
            "| epoch   3 |  1800/ 2981 batches | lr 2.95 | ms/batch 41.76 | loss  5.00 | ppl   149.08\n",
            "| epoch   3 |  2000/ 2981 batches | lr 2.95 | ms/batch 41.72 | loss  5.02 | ppl   151.74\n",
            "| epoch   3 |  2200/ 2981 batches | lr 2.95 | ms/batch 41.88 | loss  4.89 | ppl   132.34\n",
            "| epoch   3 |  2400/ 2981 batches | lr 2.95 | ms/batch 41.87 | loss  4.97 | ppl   144.53\n",
            "| epoch   3 |  2600/ 2981 batches | lr 2.95 | ms/batch 41.86 | loss  4.99 | ppl   147.23\n",
            "| epoch   3 |  2800/ 2981 batches | lr 2.95 | ms/batch 41.86 | loss  4.92 | ppl   136.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 128.83s | valid loss  5.29 | valid ppl   197.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   200/ 2981 batches | lr 2.95 | ms/batch 42.11 | loss  4.95 | ppl   141.09\n",
            "| epoch   4 |   400/ 2981 batches | lr 2.95 | ms/batch 41.97 | loss  4.97 | ppl   143.35\n",
            "| epoch   4 |   600/ 2981 batches | lr 2.95 | ms/batch 41.94 | loss  4.75 | ppl   115.45\n",
            "| epoch   4 |   800/ 2981 batches | lr 2.95 | ms/batch 41.88 | loss  4.80 | ppl   122.04\n",
            "| epoch   4 |  1000/ 2981 batches | lr 2.95 | ms/batch 41.79 | loss  4.77 | ppl   118.08\n",
            "| epoch   4 |  1200/ 2981 batches | lr 2.95 | ms/batch 41.92 | loss  4.80 | ppl   121.04\n",
            "| epoch   4 |  1400/ 2981 batches | lr 2.95 | ms/batch 41.78 | loss  4.84 | ppl   126.58\n",
            "| epoch   4 |  1600/ 2981 batches | lr 2.95 | ms/batch 41.83 | loss  4.90 | ppl   134.64\n",
            "| epoch   4 |  1800/ 2981 batches | lr 2.95 | ms/batch 41.80 | loss  4.82 | ppl   123.53\n",
            "| epoch   4 |  2000/ 2981 batches | lr 2.95 | ms/batch 41.82 | loss  4.83 | ppl   125.51\n",
            "| epoch   4 |  2200/ 2981 batches | lr 2.95 | ms/batch 41.79 | loss  4.69 | ppl   108.70\n",
            "| epoch   4 |  2400/ 2981 batches | lr 2.95 | ms/batch 41.81 | loss  4.79 | ppl   119.88\n",
            "| epoch   4 |  2600/ 2981 batches | lr 2.95 | ms/batch 41.74 | loss  4.81 | ppl   123.34\n",
            "| epoch   4 |  2800/ 2981 batches | lr 2.95 | ms/batch 41.86 | loss  4.74 | ppl   114.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 128.79s | valid loss  5.24 | valid ppl   189.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   200/ 2981 batches | lr 1.52 | ms/batch 42.01 | loss  4.71 | ppl   111.42\n",
            "| epoch   5 |   400/ 2981 batches | lr 1.52 | ms/batch 42.04 | loss  4.71 | ppl   111.35\n",
            "| epoch   5 |   600/ 2981 batches | lr 1.52 | ms/batch 41.82 | loss  4.48 | ppl    88.53\n",
            "| epoch   5 |   800/ 2981 batches | lr 1.52 | ms/batch 41.83 | loss  4.54 | ppl    93.28\n",
            "| epoch   5 |  1000/ 2981 batches | lr 1.52 | ms/batch 41.81 | loss  4.49 | ppl    89.40\n",
            "| epoch   5 |  1200/ 2981 batches | lr 1.52 | ms/batch 41.80 | loss  4.52 | ppl    91.69\n",
            "| epoch   5 |  1400/ 2981 batches | lr 1.52 | ms/batch 41.87 | loss  4.55 | ppl    94.73\n",
            "| epoch   5 |  1600/ 2981 batches | lr 1.52 | ms/batch 41.85 | loss  4.61 | ppl   100.05\n",
            "| epoch   5 |  1800/ 2981 batches | lr 1.52 | ms/batch 41.81 | loss  4.52 | ppl    91.91\n",
            "| epoch   5 |  2000/ 2981 batches | lr 1.52 | ms/batch 41.84 | loss  4.53 | ppl    92.47\n",
            "| epoch   5 |  2200/ 2981 batches | lr 1.52 | ms/batch 41.87 | loss  4.37 | ppl    79.21\n",
            "| epoch   5 |  2400/ 2981 batches | lr 1.52 | ms/batch 41.83 | loss  4.46 | ppl    86.31\n",
            "| epoch   5 |  2600/ 2981 batches | lr 1.52 | ms/batch 41.84 | loss  4.49 | ppl    89.02\n",
            "| epoch   5 |  2800/ 2981 batches | lr 1.52 | ms/batch 41.84 | loss  4.41 | ppl    82.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 128.81s | valid loss  5.13 | valid ppl   169.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   200/ 2981 batches | lr 1.52 | ms/batch 42.11 | loss  4.53 | ppl    93.12\n",
            "| epoch   6 |   400/ 2981 batches | lr 1.52 | ms/batch 42.05 | loss  4.56 | ppl    95.16\n",
            "| epoch   6 |   600/ 2981 batches | lr 1.52 | ms/batch 41.83 | loss  4.33 | ppl    75.99\n",
            "| epoch   6 |   800/ 2981 batches | lr 1.52 | ms/batch 41.86 | loss  4.39 | ppl    80.58\n",
            "| epoch   6 |  1000/ 2981 batches | lr 1.52 | ms/batch 41.94 | loss  4.36 | ppl    78.01\n",
            "| epoch   6 |  1200/ 2981 batches | lr 1.52 | ms/batch 41.92 | loss  4.39 | ppl    80.52\n",
            "| epoch   6 |  1400/ 2981 batches | lr 1.52 | ms/batch 41.98 | loss  4.43 | ppl    83.52\n",
            "| epoch   6 |  1600/ 2981 batches | lr 1.52 | ms/batch 41.98 | loss  4.48 | ppl    88.29\n",
            "| epoch   6 |  1800/ 2981 batches | lr 1.52 | ms/batch 41.86 | loss  4.41 | ppl    81.95\n",
            "| epoch   6 |  2000/ 2981 batches | lr 1.52 | ms/batch 41.80 | loss  4.41 | ppl    82.62\n",
            "| epoch   6 |  2200/ 2981 batches | lr 1.52 | ms/batch 41.88 | loss  4.27 | ppl    71.20\n",
            "| epoch   6 |  2400/ 2981 batches | lr 1.52 | ms/batch 41.92 | loss  4.35 | ppl    77.39\n",
            "| epoch   6 |  2600/ 2981 batches | lr 1.52 | ms/batch 41.96 | loss  4.39 | ppl    80.36\n",
            "| epoch   6 |  2800/ 2981 batches | lr 1.52 | ms/batch 42.03 | loss  4.31 | ppl    74.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 129.03s | valid loss  5.14 | valid ppl   170.74\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   200/ 2981 batches | lr 1.52 | ms/batch 42.17 | loss  4.42 | ppl    83.15\n",
            "| epoch   7 |   400/ 2981 batches | lr 1.52 | ms/batch 41.87 | loss  4.44 | ppl    84.78\n",
            "| epoch   7 |   600/ 2981 batches | lr 1.52 | ms/batch 41.78 | loss  4.22 | ppl    68.28\n",
            "| epoch   7 |   800/ 2981 batches | lr 1.52 | ms/batch 41.85 | loss  4.28 | ppl    72.40\n",
            "| epoch   7 |  1000/ 2981 batches | lr 1.52 | ms/batch 41.91 | loss  4.26 | ppl    70.46\n",
            "| epoch   7 |  1200/ 2981 batches | lr 1.52 | ms/batch 41.84 | loss  4.28 | ppl    72.57\n",
            "| epoch   7 |  1400/ 2981 batches | lr 1.52 | ms/batch 41.92 | loss  4.32 | ppl    75.18\n",
            "| epoch   7 |  1600/ 2981 batches | lr 1.52 | ms/batch 41.93 | loss  4.38 | ppl    80.07\n",
            "| epoch   7 |  1800/ 2981 batches | lr 1.52 | ms/batch 41.79 | loss  4.31 | ppl    74.61\n",
            "| epoch   7 |  2000/ 2981 batches | lr 1.52 | ms/batch 41.77 | loss  4.32 | ppl    75.15\n",
            "| epoch   7 |  2200/ 2981 batches | lr 1.52 | ms/batch 41.90 | loss  4.17 | ppl    64.61\n",
            "| epoch   7 |  2400/ 2981 batches | lr 1.52 | ms/batch 41.87 | loss  4.25 | ppl    70.42\n",
            "| epoch   7 |  2600/ 2981 batches | lr 1.52 | ms/batch 41.93 | loss  4.30 | ppl    73.65\n",
            "| epoch   7 |  2800/ 2981 batches | lr 1.52 | ms/batch 41.95 | loss  4.22 | ppl    68.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 128.91s | valid loss  5.16 | valid ppl   173.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   200/ 2981 batches | lr 1.52 | ms/batch 42.16 | loss  4.32 | ppl    75.44\n",
            "| epoch   8 |   400/ 2981 batches | lr 1.52 | ms/batch 41.95 | loss  4.35 | ppl    77.27\n",
            "| epoch   8 |   600/ 2981 batches | lr 1.52 | ms/batch 41.90 | loss  4.13 | ppl    62.30\n",
            "| epoch   8 |   800/ 2981 batches | lr 1.52 | ms/batch 41.93 | loss  4.19 | ppl    65.83\n",
            "| epoch   8 |  1000/ 2981 batches | lr 1.52 | ms/batch 41.86 | loss  4.17 | ppl    64.89\n",
            "| epoch   8 |  1200/ 2981 batches | lr 1.52 | ms/batch 41.91 | loss  4.20 | ppl    66.78\n",
            "| epoch   8 |  1400/ 2981 batches | lr 1.52 | ms/batch 41.94 | loss  4.24 | ppl    69.14\n",
            "| epoch   8 |  1600/ 2981 batches | lr 1.52 | ms/batch 41.85 | loss  4.30 | ppl    73.66\n",
            "| epoch   8 |  1800/ 2981 batches | lr 1.52 | ms/batch 41.82 | loss  4.23 | ppl    68.61\n",
            "| epoch   8 |  2000/ 2981 batches | lr 1.52 | ms/batch 41.93 | loss  4.24 | ppl    69.21\n",
            "| epoch   8 |  2200/ 2981 batches | lr 1.52 | ms/batch 41.85 | loss  4.09 | ppl    59.47\n",
            "| epoch   8 |  2400/ 2981 batches | lr 1.52 | ms/batch 41.91 | loss  4.17 | ppl    64.84\n",
            "| epoch   8 |  2600/ 2981 batches | lr 1.52 | ms/batch 41.89 | loss  4.22 | ppl    68.09\n",
            "| epoch   8 |  2800/ 2981 batches | lr 1.52 | ms/batch 41.97 | loss  4.14 | ppl    63.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 128.98s | valid loss  5.16 | valid ppl   174.74\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   200/ 2981 batches | lr 0.78 | ms/batch 42.12 | loss  4.23 | ppl    68.89\n",
            "| epoch   9 |   400/ 2981 batches | lr 0.78 | ms/batch 41.84 | loss  4.24 | ppl    69.27\n",
            "| epoch   9 |   600/ 2981 batches | lr 0.78 | ms/batch 41.82 | loss  4.02 | ppl    55.51\n",
            "| epoch   9 |   800/ 2981 batches | lr 0.78 | ms/batch 41.90 | loss  4.07 | ppl    58.82\n",
            "| epoch   9 |  1000/ 2981 batches | lr 0.78 | ms/batch 41.82 | loss  4.05 | ppl    57.14\n",
            "| epoch   9 |  1200/ 2981 batches | lr 0.78 | ms/batch 41.79 | loss  4.06 | ppl    58.08\n",
            "| epoch   9 |  1400/ 2981 batches | lr 0.78 | ms/batch 41.87 | loss  4.09 | ppl    59.69\n",
            "| epoch   9 |  1600/ 2981 batches | lr 0.78 | ms/batch 41.81 | loss  4.15 | ppl    63.27\n",
            "| epoch   9 |  1800/ 2981 batches | lr 0.78 | ms/batch 41.84 | loss  4.08 | ppl    58.93\n",
            "| epoch   9 |  2000/ 2981 batches | lr 0.78 | ms/batch 41.95 | loss  4.08 | ppl    59.20\n",
            "| epoch   9 |  2200/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.92 | ppl    50.32\n",
            "| epoch   9 |  2400/ 2981 batches | lr 0.78 | ms/batch 41.98 | loss  4.00 | ppl    54.48\n",
            "| epoch   9 |  2600/ 2981 batches | lr 0.78 | ms/batch 41.96 | loss  4.04 | ppl    56.87\n",
            "| epoch   9 |  2800/ 2981 batches | lr 0.78 | ms/batch 41.86 | loss  3.97 | ppl    52.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 128.92s | valid loss  5.15 | valid ppl   171.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   200/ 2981 batches | lr 0.78 | ms/batch 42.16 | loss  4.13 | ppl    62.22\n",
            "| epoch  10 |   400/ 2981 batches | lr 0.78 | ms/batch 41.83 | loss  4.15 | ppl    63.55\n",
            "| epoch  10 |   600/ 2981 batches | lr 0.78 | ms/batch 41.91 | loss  3.94 | ppl    51.27\n",
            "| epoch  10 |   800/ 2981 batches | lr 0.78 | ms/batch 41.83 | loss  4.00 | ppl    54.44\n",
            "| epoch  10 |  1000/ 2981 batches | lr 0.78 | ms/batch 41.86 | loss  3.97 | ppl    53.17\n",
            "| epoch  10 |  1200/ 2981 batches | lr 0.78 | ms/batch 41.79 | loss  4.00 | ppl    54.43\n",
            "| epoch  10 |  1400/ 2981 batches | lr 0.78 | ms/batch 41.84 | loss  4.03 | ppl    55.99\n",
            "| epoch  10 |  1600/ 2981 batches | lr 0.78 | ms/batch 41.78 | loss  4.09 | ppl    59.46\n",
            "| epoch  10 |  1800/ 2981 batches | lr 0.78 | ms/batch 41.86 | loss  4.02 | ppl    55.75\n",
            "| epoch  10 |  2000/ 2981 batches | lr 0.78 | ms/batch 41.82 | loss  4.03 | ppl    56.08\n",
            "| epoch  10 |  2200/ 2981 batches | lr 0.78 | ms/batch 41.80 | loss  3.87 | ppl    47.96\n",
            "| epoch  10 |  2400/ 2981 batches | lr 0.78 | ms/batch 41.83 | loss  3.95 | ppl    51.93\n",
            "| epoch  10 |  2600/ 2981 batches | lr 0.78 | ms/batch 41.95 | loss  3.99 | ppl    54.11\n",
            "| epoch  10 |  2800/ 2981 batches | lr 0.78 | ms/batch 41.91 | loss  3.93 | ppl    50.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 128.84s | valid loss  5.16 | valid ppl   174.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |   200/ 2981 batches | lr 0.78 | ms/batch 42.10 | loss  4.07 | ppl    58.60\n",
            "| epoch  11 |   400/ 2981 batches | lr 0.78 | ms/batch 41.86 | loss  4.09 | ppl    60.03\n",
            "| epoch  11 |   600/ 2981 batches | lr 0.78 | ms/batch 41.81 | loss  3.88 | ppl    48.51\n",
            "| epoch  11 |   800/ 2981 batches | lr 0.78 | ms/batch 41.82 | loss  3.94 | ppl    51.46\n",
            "| epoch  11 |  1000/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.92 | ppl    50.57\n",
            "| epoch  11 |  1200/ 2981 batches | lr 0.78 | ms/batch 41.85 | loss  3.94 | ppl    51.67\n",
            "| epoch  11 |  1400/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.97 | ppl    53.08\n",
            "| epoch  11 |  1600/ 2981 batches | lr 0.78 | ms/batch 41.91 | loss  4.03 | ppl    56.39\n",
            "| epoch  11 |  1800/ 2981 batches | lr 0.78 | ms/batch 41.94 | loss  3.97 | ppl    53.07\n",
            "| epoch  11 |  2000/ 2981 batches | lr 0.78 | ms/batch 41.91 | loss  3.98 | ppl    53.41\n",
            "| epoch  11 |  2200/ 2981 batches | lr 0.78 | ms/batch 41.88 | loss  3.82 | ppl    45.58\n",
            "| epoch  11 |  2400/ 2981 batches | lr 0.78 | ms/batch 41.84 | loss  3.91 | ppl    49.68\n",
            "| epoch  11 |  2600/ 2981 batches | lr 0.78 | ms/batch 41.90 | loss  3.95 | ppl    52.04\n",
            "| epoch  11 |  2800/ 2981 batches | lr 0.78 | ms/batch 41.92 | loss  3.88 | ppl    48.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 128.93s | valid loss  5.19 | valid ppl   179.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |   200/ 2981 batches | lr 0.78 | ms/batch 42.23 | loss  4.02 | ppl    55.79\n",
            "| epoch  12 |   400/ 2981 batches | lr 0.78 | ms/batch 41.90 | loss  4.04 | ppl    56.90\n",
            "| epoch  12 |   600/ 2981 batches | lr 0.78 | ms/batch 41.85 | loss  3.83 | ppl    46.28\n",
            "| epoch  12 |   800/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.89 | ppl    48.91\n",
            "| epoch  12 |  1000/ 2981 batches | lr 0.78 | ms/batch 41.91 | loss  3.87 | ppl    48.11\n",
            "| epoch  12 |  1200/ 2981 batches | lr 0.78 | ms/batch 41.92 | loss  3.90 | ppl    49.38\n",
            "| epoch  12 |  1400/ 2981 batches | lr 0.78 | ms/batch 41.95 | loss  3.92 | ppl    50.62\n",
            "| epoch  12 |  1600/ 2981 batches | lr 0.78 | ms/batch 41.79 | loss  3.99 | ppl    53.93\n",
            "| epoch  12 |  1800/ 2981 batches | lr 0.78 | ms/batch 41.98 | loss  3.93 | ppl    50.80\n",
            "| epoch  12 |  2000/ 2981 batches | lr 0.78 | ms/batch 41.83 | loss  3.93 | ppl    51.05\n",
            "| epoch  12 |  2200/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.78 | ppl    43.85\n",
            "| epoch  12 |  2400/ 2981 batches | lr 0.78 | ms/batch 41.90 | loss  3.86 | ppl    47.39\n",
            "| epoch  12 |  2600/ 2981 batches | lr 0.78 | ms/batch 41.89 | loss  3.91 | ppl    49.79\n",
            "| epoch  12 |  2800/ 2981 batches | lr 0.78 | ms/batch 41.80 | loss  3.84 | ppl    46.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 128.94s | valid loss  5.20 | valid ppl   181.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |   200/ 2981 batches | lr 0.40 | ms/batch 42.15 | loss  3.99 | ppl    53.98\n",
            "| epoch  13 |   400/ 2981 batches | lr 0.40 | ms/batch 41.83 | loss  4.00 | ppl    54.82\n",
            "| epoch  13 |   600/ 2981 batches | lr 0.40 | ms/batch 41.88 | loss  3.79 | ppl    44.41\n",
            "| epoch  13 |   800/ 2981 batches | lr 0.40 | ms/batch 41.95 | loss  3.85 | ppl    46.84\n",
            "| epoch  13 |  1000/ 2981 batches | lr 0.40 | ms/batch 41.82 | loss  3.83 | ppl    45.99\n",
            "| epoch  13 |  1200/ 2981 batches | lr 0.40 | ms/batch 41.80 | loss  3.84 | ppl    46.61\n",
            "| epoch  13 |  1400/ 2981 batches | lr 0.40 | ms/batch 41.84 | loss  3.86 | ppl    47.37\n",
            "| epoch  13 |  1600/ 2981 batches | lr 0.40 | ms/batch 41.85 | loss  3.92 | ppl    50.42\n",
            "| epoch  13 |  1800/ 2981 batches | lr 0.40 | ms/batch 41.82 | loss  3.85 | ppl    47.14\n",
            "| epoch  13 |  2000/ 2981 batches | lr 0.40 | ms/batch 41.92 | loss  3.86 | ppl    47.51\n",
            "| epoch  13 |  2200/ 2981 batches | lr 0.40 | ms/batch 41.85 | loss  3.70 | ppl    40.34\n",
            "| epoch  13 |  2400/ 2981 batches | lr 0.40 | ms/batch 41.77 | loss  3.78 | ppl    43.66\n",
            "| epoch  13 |  2600/ 2981 batches | lr 0.40 | ms/batch 41.85 | loss  3.82 | ppl    45.46\n",
            "| epoch  13 |  2800/ 2981 batches | lr 0.40 | ms/batch 41.80 | loss  3.75 | ppl    42.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 128.86s | valid loss  5.18 | valid ppl   177.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |   200/ 2981 batches | lr 0.40 | ms/batch 42.12 | loss  3.94 | ppl    51.25\n",
            "| epoch  14 |   400/ 2981 batches | lr 0.40 | ms/batch 41.92 | loss  3.95 | ppl    51.98\n",
            "| epoch  14 |   600/ 2981 batches | lr 0.40 | ms/batch 41.85 | loss  3.75 | ppl    42.40\n",
            "| epoch  14 |   800/ 2981 batches | lr 0.40 | ms/batch 41.97 | loss  3.80 | ppl    44.74\n",
            "| epoch  14 |  1000/ 2981 batches | lr 0.40 | ms/batch 41.86 | loss  3.79 | ppl    44.09\n",
            "| epoch  14 |  1200/ 2981 batches | lr 0.40 | ms/batch 41.85 | loss  3.81 | ppl    45.08\n",
            "| epoch  14 |  1400/ 2981 batches | lr 0.40 | ms/batch 41.98 | loss  3.83 | ppl    46.03\n",
            "| epoch  14 |  1600/ 2981 batches | lr 0.40 | ms/batch 41.89 | loss  3.88 | ppl    48.65\n",
            "| epoch  14 |  1800/ 2981 batches | lr 0.40 | ms/batch 41.98 | loss  3.83 | ppl    45.93\n",
            "| epoch  14 |  2000/ 2981 batches | lr 0.40 | ms/batch 41.87 | loss  3.83 | ppl    46.20\n",
            "| epoch  14 |  2200/ 2981 batches | lr 0.40 | ms/batch 41.95 | loss  3.67 | ppl    39.23\n",
            "| epoch  14 |  2400/ 2981 batches | lr 0.40 | ms/batch 41.82 | loss  3.75 | ppl    42.54\n",
            "| epoch  14 |  2600/ 2981 batches | lr 0.40 | ms/batch 41.87 | loss  3.79 | ppl    44.46\n",
            "| epoch  14 |  2800/ 2981 batches | lr 0.40 | ms/batch 41.96 | loss  3.73 | ppl    41.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 128.98s | valid loss  5.19 | valid ppl   179.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |   200/ 2981 batches | lr 0.40 | ms/batch 42.13 | loss  3.90 | ppl    49.44\n",
            "| epoch  15 |   400/ 2981 batches | lr 0.40 | ms/batch 41.95 | loss  3.92 | ppl    50.50\n",
            "| epoch  15 |   600/ 2981 batches | lr 0.40 | ms/batch 41.76 | loss  3.72 | ppl    41.16\n",
            "| epoch  15 |   800/ 2981 batches | lr 0.40 | ms/batch 41.83 | loss  3.77 | ppl    43.44\n",
            "| epoch  15 |  1000/ 2981 batches | lr 0.40 | ms/batch 41.87 | loss  3.76 | ppl    43.03\n",
            "| epoch  15 |  1200/ 2981 batches | lr 0.40 | ms/batch 41.97 | loss  3.78 | ppl    43.61\n",
            "| epoch  15 |  1400/ 2981 batches | lr 0.40 | ms/batch 41.84 | loss  3.80 | ppl    44.53\n",
            "| epoch  15 |  1600/ 2981 batches | lr 0.40 | ms/batch 41.80 | loss  3.86 | ppl    47.30\n",
            "| epoch  15 |  1800/ 2981 batches | lr 0.40 | ms/batch 41.80 | loss  3.81 | ppl    44.98\n",
            "| epoch  15 |  2000/ 2981 batches | lr 0.40 | ms/batch 41.96 | loss  3.81 | ppl    45.24\n",
            "| epoch  15 |  2200/ 2981 batches | lr 0.40 | ms/batch 41.93 | loss  3.65 | ppl    38.44\n",
            "| epoch  15 |  2400/ 2981 batches | lr 0.40 | ms/batch 41.80 | loss  3.73 | ppl    41.49\n",
            "| epoch  15 |  2600/ 2981 batches | lr 0.40 | ms/batch 41.84 | loss  3.78 | ppl    43.61\n",
            "| epoch  15 |  2800/ 2981 batches | lr 0.40 | ms/batch 42.03 | loss  3.70 | ppl    40.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 128.90s | valid loss  5.20 | valid ppl   181.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |   200/ 2981 batches | lr 0.40 | ms/batch 42.16 | loss  3.87 | ppl    48.00\n",
            "| epoch  16 |   400/ 2981 batches | lr 0.40 | ms/batch 41.92 | loss  3.89 | ppl    48.79\n",
            "| epoch  16 |   600/ 2981 batches | lr 0.40 | ms/batch 41.94 | loss  3.69 | ppl    39.91\n",
            "| epoch  16 |   800/ 2981 batches | lr 0.40 | ms/batch 41.93 | loss  3.74 | ppl    42.29\n",
            "| epoch  16 |  1000/ 2981 batches | lr 0.40 | ms/batch 41.93 | loss  3.73 | ppl    41.88\n",
            "| epoch  16 |  1200/ 2981 batches | lr 0.40 | ms/batch 41.97 | loss  3.75 | ppl    42.44\n",
            "| epoch  16 |  1400/ 2981 batches | lr 0.40 | ms/batch 41.92 | loss  3.77 | ppl    43.49\n",
            "| epoch  16 |  1600/ 2981 batches | lr 0.40 | ms/batch 41.88 | loss  3.83 | ppl    46.18\n",
            "| epoch  16 |  1800/ 2981 batches | lr 0.40 | ms/batch 41.90 | loss  3.78 | ppl    43.79\n",
            "| epoch  16 |  2000/ 2981 batches | lr 0.40 | ms/batch 41.83 | loss  3.79 | ppl    44.19\n",
            "| epoch  16 |  2200/ 2981 batches | lr 0.40 | ms/batch 41.96 | loss  3.63 | ppl    37.55\n",
            "| epoch  16 |  2400/ 2981 batches | lr 0.40 | ms/batch 41.88 | loss  3.70 | ppl    40.50\n",
            "| epoch  16 |  2600/ 2981 batches | lr 0.40 | ms/batch 41.92 | loss  3.75 | ppl    42.50\n",
            "| epoch  16 |  2800/ 2981 batches | lr 0.40 | ms/batch 41.89 | loss  3.69 | ppl    39.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 129.01s | valid loss  5.22 | valid ppl   184.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |   200/ 2981 batches | lr 0.21 | ms/batch 42.17 | loss  3.87 | ppl    47.99\n",
            "| epoch  17 |   400/ 2981 batches | lr 0.21 | ms/batch 41.94 | loss  3.89 | ppl    49.07\n",
            "| epoch  17 |   600/ 2981 batches | lr 0.21 | ms/batch 41.89 | loss  3.69 | ppl    39.85\n",
            "| epoch  17 |   800/ 2981 batches | lr 0.21 | ms/batch 41.94 | loss  3.74 | ppl    42.08\n",
            "| epoch  17 |  1000/ 2981 batches | lr 0.21 | ms/batch 41.87 | loss  3.73 | ppl    41.56\n",
            "| epoch  17 |  1200/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.74 | ppl    42.02\n",
            "| epoch  17 |  1400/ 2981 batches | lr 0.21 | ms/batch 41.92 | loss  3.75 | ppl    42.65\n",
            "| epoch  17 |  1600/ 2981 batches | lr 0.21 | ms/batch 41.93 | loss  3.81 | ppl    45.20\n",
            "| epoch  17 |  1800/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.75 | ppl    42.68\n",
            "| epoch  17 |  2000/ 2981 batches | lr 0.21 | ms/batch 41.92 | loss  3.76 | ppl    43.00\n",
            "| epoch  17 |  2200/ 2981 batches | lr 0.21 | ms/batch 42.03 | loss  3.59 | ppl    36.41\n",
            "| epoch  17 |  2400/ 2981 batches | lr 0.21 | ms/batch 41.88 | loss  3.67 | ppl    39.13\n",
            "| epoch  17 |  2600/ 2981 batches | lr 0.21 | ms/batch 41.84 | loss  3.71 | ppl    40.94\n",
            "| epoch  17 |  2800/ 2981 batches | lr 0.21 | ms/batch 41.88 | loss  3.65 | ppl    38.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 129.04s | valid loss  5.20 | valid ppl   180.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |   200/ 2981 batches | lr 0.21 | ms/batch 42.14 | loss  3.85 | ppl    46.81\n",
            "| epoch  18 |   400/ 2981 batches | lr 0.21 | ms/batch 41.96 | loss  3.86 | ppl    47.43\n",
            "| epoch  18 |   600/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.66 | ppl    38.91\n",
            "| epoch  18 |   800/ 2981 batches | lr 0.21 | ms/batch 41.81 | loss  3.71 | ppl    41.00\n",
            "| epoch  18 |  1000/ 2981 batches | lr 0.21 | ms/batch 41.84 | loss  3.70 | ppl    40.47\n",
            "| epoch  18 |  1200/ 2981 batches | lr 0.21 | ms/batch 41.85 | loss  3.71 | ppl    41.05\n",
            "| epoch  18 |  1400/ 2981 batches | lr 0.21 | ms/batch 41.95 | loss  3.73 | ppl    41.60\n",
            "| epoch  18 |  1600/ 2981 batches | lr 0.21 | ms/batch 41.88 | loss  3.79 | ppl    44.45\n",
            "| epoch  18 |  1800/ 2981 batches | lr 0.21 | ms/batch 41.86 | loss  3.74 | ppl    41.97\n",
            "| epoch  18 |  2000/ 2981 batches | lr 0.21 | ms/batch 42.00 | loss  3.75 | ppl    42.42\n",
            "| epoch  18 |  2200/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.58 | ppl    36.04\n",
            "| epoch  18 |  2400/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.66 | ppl    38.74\n",
            "| epoch  18 |  2600/ 2981 batches | lr 0.21 | ms/batch 41.84 | loss  3.70 | ppl    40.41\n",
            "| epoch  18 |  2800/ 2981 batches | lr 0.21 | ms/batch 41.96 | loss  3.64 | ppl    38.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 128.97s | valid loss  5.20 | valid ppl   181.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |   200/ 2981 batches | lr 0.21 | ms/batch 42.09 | loss  3.82 | ppl    45.73\n",
            "| epoch  19 |   400/ 2981 batches | lr 0.21 | ms/batch 42.05 | loss  3.84 | ppl    46.52\n",
            "| epoch  19 |   600/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.65 | ppl    38.37\n",
            "| epoch  19 |   800/ 2981 batches | lr 0.21 | ms/batch 41.89 | loss  3.69 | ppl    40.22\n",
            "| epoch  19 |  1000/ 2981 batches | lr 0.21 | ms/batch 41.91 | loss  3.68 | ppl    39.83\n",
            "| epoch  19 |  1200/ 2981 batches | lr 0.21 | ms/batch 41.96 | loss  3.70 | ppl    40.47\n",
            "| epoch  19 |  1400/ 2981 batches | lr 0.21 | ms/batch 41.88 | loss  3.71 | ppl    41.05\n",
            "| epoch  19 |  1600/ 2981 batches | lr 0.21 | ms/batch 41.89 | loss  3.77 | ppl    43.51\n",
            "| epoch  19 |  1800/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.72 | ppl    41.34\n",
            "| epoch  19 |  2000/ 2981 batches | lr 0.21 | ms/batch 41.87 | loss  3.73 | ppl    41.85\n",
            "| epoch  19 |  2200/ 2981 batches | lr 0.21 | ms/batch 41.89 | loss  3.57 | ppl    35.52\n",
            "| epoch  19 |  2400/ 2981 batches | lr 0.21 | ms/batch 41.90 | loss  3.64 | ppl    38.09\n",
            "| epoch  19 |  2600/ 2981 batches | lr 0.21 | ms/batch 41.98 | loss  3.69 | ppl    39.99\n",
            "| epoch  19 |  2800/ 2981 batches | lr 0.21 | ms/batch 41.86 | loss  3.63 | ppl    37.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 129.00s | valid loss  5.21 | valid ppl   182.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |   200/ 2981 batches | lr 0.21 | ms/batch 42.24 | loss  3.81 | ppl    44.97\n",
            "| epoch  20 |   400/ 2981 batches | lr 0.21 | ms/batch 41.86 | loss  3.83 | ppl    45.83\n",
            "| epoch  20 |   600/ 2981 batches | lr 0.21 | ms/batch 41.87 | loss  3.63 | ppl    37.71\n",
            "| epoch  20 |   800/ 2981 batches | lr 0.21 | ms/batch 41.81 | loss  3.68 | ppl    39.73\n",
            "| epoch  20 |  1000/ 2981 batches | lr 0.21 | ms/batch 41.88 | loss  3.67 | ppl    39.12\n",
            "| epoch  20 |  1200/ 2981 batches | lr 0.21 | ms/batch 41.77 | loss  3.68 | ppl    39.78\n",
            "| epoch  20 |  1400/ 2981 batches | lr 0.21 | ms/batch 41.86 | loss  3.70 | ppl    40.53\n",
            "| epoch  20 |  1600/ 2981 batches | lr 0.21 | ms/batch 41.83 | loss  3.76 | ppl    42.91\n",
            "| epoch  20 |  1800/ 2981 batches | lr 0.21 | ms/batch 41.91 | loss  3.71 | ppl    40.93\n",
            "| epoch  20 |  2000/ 2981 batches | lr 0.21 | ms/batch 41.85 | loss  3.72 | ppl    41.25\n",
            "| epoch  20 |  2200/ 2981 batches | lr 0.21 | ms/batch 41.81 | loss  3.56 | ppl    35.12\n",
            "| epoch  20 |  2400/ 2981 batches | lr 0.21 | ms/batch 41.89 | loss  3.63 | ppl    37.72\n",
            "| epoch  20 |  2600/ 2981 batches | lr 0.21 | ms/batch 41.81 | loss  3.68 | ppl    39.48\n",
            "| epoch  20 |  2800/ 2981 batches | lr 0.21 | ms/batch 41.76 | loss  3.62 | ppl    37.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 128.86s | valid loss  5.21 | valid ppl   183.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |   200/ 2981 batches | lr 0.11 | ms/batch 42.09 | loss  3.82 | ppl    45.63\n",
            "| epoch  21 |   400/ 2981 batches | lr 0.11 | ms/batch 41.80 | loss  3.85 | ppl    46.97\n",
            "| epoch  21 |   600/ 2981 batches | lr 0.11 | ms/batch 41.84 | loss  3.65 | ppl    38.31\n",
            "| epoch  21 |   800/ 2981 batches | lr 0.11 | ms/batch 41.85 | loss  3.70 | ppl    40.38\n",
            "| epoch  21 |  1000/ 2981 batches | lr 0.11 | ms/batch 41.88 | loss  3.68 | ppl    39.80\n",
            "| epoch  21 |  1200/ 2981 batches | lr 0.11 | ms/batch 41.94 | loss  3.70 | ppl    40.32\n",
            "| epoch  21 |  1400/ 2981 batches | lr 0.11 | ms/batch 41.80 | loss  3.71 | ppl    40.74\n",
            "| epoch  21 |  1600/ 2981 batches | lr 0.11 | ms/batch 41.80 | loss  3.77 | ppl    43.24\n",
            "| epoch  21 |  1800/ 2981 batches | lr 0.11 | ms/batch 41.77 | loss  3.71 | ppl    41.01\n",
            "| epoch  21 |  2000/ 2981 batches | lr 0.11 | ms/batch 41.83 | loss  3.72 | ppl    41.26\n",
            "| epoch  21 |  2200/ 2981 batches | lr 0.11 | ms/batch 41.84 | loss  3.55 | ppl    34.86\n",
            "| epoch  21 |  2400/ 2981 batches | lr 0.11 | ms/batch 41.86 | loss  3.62 | ppl    37.43\n",
            "| epoch  21 |  2600/ 2981 batches | lr 0.11 | ms/batch 41.81 | loss  3.66 | ppl    39.05\n",
            "| epoch  21 |  2800/ 2981 batches | lr 0.11 | ms/batch 41.98 | loss  3.61 | ppl    36.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 128.84s | valid loss  5.20 | valid ppl   181.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |   200/ 2981 batches | lr 0.11 | ms/batch 42.07 | loss  3.81 | ppl    45.02\n",
            "| epoch  22 |   400/ 2981 batches | lr 0.11 | ms/batch 41.78 | loss  3.83 | ppl    45.97\n",
            "| epoch  22 |   600/ 2981 batches | lr 0.11 | ms/batch 41.88 | loss  3.63 | ppl    37.53\n",
            "| epoch  22 |   800/ 2981 batches | lr 0.11 | ms/batch 41.87 | loss  3.68 | ppl    39.71\n",
            "| epoch  22 |  1000/ 2981 batches | lr 0.11 | ms/batch 41.79 | loss  3.67 | ppl    39.31\n",
            "| epoch  22 |  1200/ 2981 batches | lr 0.11 | ms/batch 42.06 | loss  3.68 | ppl    39.74\n",
            "| epoch  22 |  1400/ 2981 batches | lr 0.11 | ms/batch 41.90 | loss  3.70 | ppl    40.27\n",
            "| epoch  22 |  1600/ 2981 batches | lr 0.11 | ms/batch 41.91 | loss  3.75 | ppl    42.64\n",
            "| epoch  22 |  1800/ 2981 batches | lr 0.11 | ms/batch 41.87 | loss  3.70 | ppl    40.54\n",
            "| epoch  22 |  2000/ 2981 batches | lr 0.11 | ms/batch 41.88 | loss  3.71 | ppl    40.80\n",
            "| epoch  22 |  2200/ 2981 batches | lr 0.11 | ms/batch 41.85 | loss  3.55 | ppl    34.68\n",
            "| epoch  22 |  2400/ 2981 batches | lr 0.11 | ms/batch 41.86 | loss  3.62 | ppl    37.24\n",
            "| epoch  22 |  2600/ 2981 batches | lr 0.11 | ms/batch 41.99 | loss  3.66 | ppl    38.92\n",
            "| epoch  22 |  2800/ 2981 batches | lr 0.11 | ms/batch 42.00 | loss  3.60 | ppl    36.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 128.94s | valid loss  5.21 | valid ppl   182.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |   200/ 2981 batches | lr 0.11 | ms/batch 42.10 | loss  3.79 | ppl    44.42\n",
            "| epoch  23 |   400/ 2981 batches | lr 0.11 | ms/batch 41.95 | loss  3.82 | ppl    45.38\n",
            "| epoch  23 |   600/ 2981 batches | lr 0.11 | ms/batch 41.90 | loss  3.62 | ppl    37.20\n",
            "| epoch  23 |   800/ 2981 batches | lr 0.11 | ms/batch 41.94 | loss  3.67 | ppl    39.29\n",
            "| epoch  23 |  1000/ 2981 batches | lr 0.11 | ms/batch 41.89 | loss  3.66 | ppl    38.90\n",
            "| epoch  23 |  1200/ 2981 batches | lr 0.11 | ms/batch 41.89 | loss  3.67 | ppl    39.36\n",
            "| epoch  23 |  1400/ 2981 batches | lr 0.11 | ms/batch 41.88 | loss  3.69 | ppl    39.92\n",
            "| epoch  23 |  1600/ 2981 batches | lr 0.11 | ms/batch 41.98 | loss  3.75 | ppl    42.43\n",
            "| epoch  23 |  1800/ 2981 batches | lr 0.11 | ms/batch 41.89 | loss  3.70 | ppl    40.33\n",
            "| epoch  23 |  2000/ 2981 batches | lr 0.11 | ms/batch 41.91 | loss  3.70 | ppl    40.53\n",
            "| epoch  23 |  2200/ 2981 batches | lr 0.11 | ms/batch 41.93 | loss  3.54 | ppl    34.48\n",
            "| epoch  23 |  2400/ 2981 batches | lr 0.11 | ms/batch 41.90 | loss  3.61 | ppl    36.92\n",
            "| epoch  23 |  2600/ 2981 batches | lr 0.11 | ms/batch 41.95 | loss  3.66 | ppl    38.78\n",
            "| epoch  23 |  2800/ 2981 batches | lr 0.11 | ms/batch 41.90 | loss  3.60 | ppl    36.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 129.03s | valid loss  5.21 | valid ppl   182.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |   200/ 2981 batches | lr 0.11 | ms/batch 42.11 | loss  3.78 | ppl    43.83\n",
            "| epoch  24 |   400/ 2981 batches | lr 0.11 | ms/batch 41.89 | loss  3.80 | ppl    44.84\n",
            "| epoch  24 |   600/ 2981 batches | lr 0.11 | ms/batch 41.76 | loss  3.61 | ppl    36.94\n",
            "| epoch  24 |   800/ 2981 batches | lr 0.11 | ms/batch 41.91 | loss  3.66 | ppl    39.04\n",
            "| epoch  24 |  1000/ 2981 batches | lr 0.11 | ms/batch 41.95 | loss  3.65 | ppl    38.64\n",
            "| epoch  24 |  1200/ 2981 batches | lr 0.11 | ms/batch 41.78 | loss  3.66 | ppl    39.00\n",
            "| epoch  24 |  1400/ 2981 batches | lr 0.11 | ms/batch 41.87 | loss  3.68 | ppl    39.55\n",
            "| epoch  24 |  1600/ 2981 batches | lr 0.11 | ms/batch 41.82 | loss  3.74 | ppl    42.01\n",
            "| epoch  24 |  1800/ 2981 batches | lr 0.11 | ms/batch 41.94 | loss  3.69 | ppl    39.96\n",
            "| epoch  24 |  2000/ 2981 batches | lr 0.11 | ms/batch 41.91 | loss  3.70 | ppl    40.36\n",
            "| epoch  24 |  2200/ 2981 batches | lr 0.11 | ms/batch 41.90 | loss  3.54 | ppl    34.35\n",
            "| epoch  24 |  2400/ 2981 batches | lr 0.11 | ms/batch 41.93 | loss  3.60 | ppl    36.74\n",
            "| epoch  24 |  2600/ 2981 batches | lr 0.11 | ms/batch 41.98 | loss  3.65 | ppl    38.49\n",
            "| epoch  24 |  2800/ 2981 batches | lr 0.11 | ms/batch 41.87 | loss  3.59 | ppl    36.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 128.92s | valid loss  5.21 | valid ppl   183.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |   200/ 2981 batches | lr 0.05 | ms/batch 42.24 | loss  3.81 | ppl    44.97\n",
            "| epoch  25 |   400/ 2981 batches | lr 0.05 | ms/batch 41.95 | loss  3.83 | ppl    46.17\n",
            "| epoch  25 |   600/ 2981 batches | lr 0.05 | ms/batch 41.80 | loss  3.63 | ppl    37.83\n",
            "| epoch  25 |   800/ 2981 batches | lr 0.05 | ms/batch 41.85 | loss  3.69 | ppl    40.14\n",
            "| epoch  25 |  1000/ 2981 batches | lr 0.05 | ms/batch 41.82 | loss  3.68 | ppl    39.54\n",
            "| epoch  25 |  1200/ 2981 batches | lr 0.05 | ms/batch 41.91 | loss  3.69 | ppl    39.96\n",
            "| epoch  25 |  1400/ 2981 batches | lr 0.05 | ms/batch 41.96 | loss  3.70 | ppl    40.28\n",
            "| epoch  25 |  1600/ 2981 batches | lr 0.05 | ms/batch 41.97 | loss  3.75 | ppl    42.63\n",
            "| epoch  25 |  1800/ 2981 batches | lr 0.05 | ms/batch 41.97 | loss  3.70 | ppl    40.56\n",
            "| epoch  25 |  2000/ 2981 batches | lr 0.05 | ms/batch 42.03 | loss  3.70 | ppl    40.58\n",
            "| epoch  25 |  2200/ 2981 batches | lr 0.05 | ms/batch 41.93 | loss  3.54 | ppl    34.50\n",
            "| epoch  25 |  2400/ 2981 batches | lr 0.05 | ms/batch 41.92 | loss  3.61 | ppl    36.99\n",
            "| epoch  25 |  2600/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.65 | ppl    38.54\n",
            "| epoch  25 |  2800/ 2981 batches | lr 0.05 | ms/batch 42.00 | loss  3.60 | ppl    36.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 129.09s | valid loss  5.20 | valid ppl   180.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |   200/ 2981 batches | lr 0.05 | ms/batch 42.24 | loss  3.80 | ppl    44.55\n",
            "| epoch  26 |   400/ 2981 batches | lr 0.05 | ms/batch 42.09 | loss  3.82 | ppl    45.48\n",
            "| epoch  26 |   600/ 2981 batches | lr 0.05 | ms/batch 42.11 | loss  3.62 | ppl    37.37\n",
            "| epoch  26 |   800/ 2981 batches | lr 0.05 | ms/batch 41.97 | loss  3.68 | ppl    39.75\n",
            "| epoch  26 |  1000/ 2981 batches | lr 0.05 | ms/batch 41.90 | loss  3.66 | ppl    38.87\n",
            "| epoch  26 |  1200/ 2981 batches | lr 0.05 | ms/batch 42.04 | loss  3.68 | ppl    39.48\n",
            "| epoch  26 |  1400/ 2981 batches | lr 0.05 | ms/batch 42.02 | loss  3.69 | ppl    39.94\n",
            "| epoch  26 |  1600/ 2981 batches | lr 0.05 | ms/batch 41.98 | loss  3.74 | ppl    42.30\n",
            "| epoch  26 |  1800/ 2981 batches | lr 0.05 | ms/batch 41.94 | loss  3.69 | ppl    40.24\n",
            "| epoch  26 |  2000/ 2981 batches | lr 0.05 | ms/batch 41.97 | loss  3.70 | ppl    40.50\n",
            "| epoch  26 |  2200/ 2981 batches | lr 0.05 | ms/batch 42.05 | loss  3.54 | ppl    34.51\n",
            "| epoch  26 |  2400/ 2981 batches | lr 0.05 | ms/batch 42.04 | loss  3.61 | ppl    36.96\n",
            "| epoch  26 |  2600/ 2981 batches | lr 0.05 | ms/batch 41.97 | loss  3.65 | ppl    38.54\n",
            "| epoch  26 |  2800/ 2981 batches | lr 0.05 | ms/batch 42.03 | loss  3.60 | ppl    36.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 129.27s | valid loss  5.20 | valid ppl   181.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |   200/ 2981 batches | lr 0.05 | ms/batch 42.31 | loss  3.79 | ppl    44.36\n",
            "| epoch  27 |   400/ 2981 batches | lr 0.05 | ms/batch 41.87 | loss  3.81 | ppl    45.15\n",
            "| epoch  27 |   600/ 2981 batches | lr 0.05 | ms/batch 41.94 | loss  3.61 | ppl    37.05\n",
            "| epoch  27 |   800/ 2981 batches | lr 0.05 | ms/batch 41.82 | loss  3.68 | ppl    39.56\n",
            "| epoch  27 |  1000/ 2981 batches | lr 0.05 | ms/batch 41.90 | loss  3.66 | ppl    38.79\n",
            "| epoch  27 |  1200/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.67 | ppl    39.22\n",
            "| epoch  27 |  1400/ 2981 batches | lr 0.05 | ms/batch 42.07 | loss  3.68 | ppl    39.78\n",
            "| epoch  27 |  1600/ 2981 batches | lr 0.05 | ms/batch 41.86 | loss  3.74 | ppl    42.13\n",
            "| epoch  27 |  1800/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.69 | ppl    39.97\n",
            "| epoch  27 |  2000/ 2981 batches | lr 0.05 | ms/batch 41.92 | loss  3.69 | ppl    40.19\n",
            "| epoch  27 |  2200/ 2981 batches | lr 0.05 | ms/batch 41.92 | loss  3.53 | ppl    34.27\n",
            "| epoch  27 |  2400/ 2981 batches | lr 0.05 | ms/batch 41.82 | loss  3.60 | ppl    36.72\n",
            "| epoch  27 |  2600/ 2981 batches | lr 0.05 | ms/batch 41.96 | loss  3.65 | ppl    38.49\n",
            "| epoch  27 |  2800/ 2981 batches | lr 0.05 | ms/batch 41.81 | loss  3.59 | ppl    36.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 129.04s | valid loss  5.20 | valid ppl   181.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |   200/ 2981 batches | lr 0.05 | ms/batch 42.20 | loss  3.78 | ppl    43.87\n",
            "| epoch  28 |   400/ 2981 batches | lr 0.05 | ms/batch 41.91 | loss  3.80 | ppl    44.91\n",
            "| epoch  28 |   600/ 2981 batches | lr 0.05 | ms/batch 41.88 | loss  3.60 | ppl    36.74\n",
            "| epoch  28 |   800/ 2981 batches | lr 0.05 | ms/batch 41.96 | loss  3.67 | ppl    39.25\n",
            "| epoch  28 |  1000/ 2981 batches | lr 0.05 | ms/batch 41.84 | loss  3.65 | ppl    38.43\n",
            "| epoch  28 |  1200/ 2981 batches | lr 0.05 | ms/batch 41.95 | loss  3.66 | ppl    38.98\n",
            "| epoch  28 |  1400/ 2981 batches | lr 0.05 | ms/batch 41.99 | loss  3.68 | ppl    39.57\n",
            "| epoch  28 |  1600/ 2981 batches | lr 0.05 | ms/batch 41.91 | loss  3.74 | ppl    41.91\n",
            "| epoch  28 |  1800/ 2981 batches | lr 0.05 | ms/batch 41.80 | loss  3.68 | ppl    39.76\n",
            "| epoch  28 |  2000/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.69 | ppl    40.03\n",
            "| epoch  28 |  2200/ 2981 batches | lr 0.05 | ms/batch 41.92 | loss  3.53 | ppl    34.16\n",
            "| epoch  28 |  2400/ 2981 batches | lr 0.05 | ms/batch 41.87 | loss  3.60 | ppl    36.75\n",
            "| epoch  28 |  2600/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.65 | ppl    38.48\n",
            "| epoch  28 |  2800/ 2981 batches | lr 0.05 | ms/batch 41.89 | loss  3.59 | ppl    36.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 128.97s | valid loss  5.20 | valid ppl   181.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |   200/ 2981 batches | lr 0.03 | ms/batch 42.00 | loss  3.80 | ppl    44.82\n",
            "| epoch  29 |   400/ 2981 batches | lr 0.03 | ms/batch 41.93 | loss  3.83 | ppl    46.15\n",
            "| epoch  29 |   600/ 2981 batches | lr 0.03 | ms/batch 41.86 | loss  3.63 | ppl    37.67\n",
            "| epoch  29 |   800/ 2981 batches | lr 0.03 | ms/batch 41.83 | loss  3.71 | ppl    40.66\n",
            "| epoch  29 |  1000/ 2981 batches | lr 0.03 | ms/batch 41.76 | loss  3.67 | ppl    39.34\n",
            "| epoch  29 |  1200/ 2981 batches | lr 0.03 | ms/batch 41.94 | loss  3.68 | ppl    39.57\n",
            "| epoch  29 |  1400/ 2981 batches | lr 0.03 | ms/batch 41.97 | loss  3.70 | ppl    40.25\n",
            "| epoch  29 |  1600/ 2981 batches | lr 0.03 | ms/batch 41.93 | loss  3.75 | ppl    42.64\n",
            "| epoch  29 |  1800/ 2981 batches | lr 0.03 | ms/batch 41.83 | loss  3.70 | ppl    40.40\n",
            "| epoch  29 |  2000/ 2981 batches | lr 0.03 | ms/batch 41.85 | loss  3.71 | ppl    40.65\n",
            "| epoch  29 |  2200/ 2981 batches | lr 0.03 | ms/batch 41.93 | loss  3.54 | ppl    34.56\n",
            "| epoch  29 |  2400/ 2981 batches | lr 0.03 | ms/batch 41.89 | loss  3.62 | ppl    37.36\n",
            "| epoch  29 |  2600/ 2981 batches | lr 0.03 | ms/batch 41.96 | loss  3.66 | ppl    38.69\n",
            "| epoch  29 |  2800/ 2981 batches | lr 0.03 | ms/batch 41.88 | loss  3.60 | ppl    36.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 128.93s | valid loss  5.19 | valid ppl   178.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |   200/ 2981 batches | lr 0.03 | ms/batch 42.17 | loss  3.80 | ppl    44.48\n",
            "| epoch  30 |   400/ 2981 batches | lr 0.03 | ms/batch 41.91 | loss  3.82 | ppl    45.64\n",
            "| epoch  30 |   600/ 2981 batches | lr 0.03 | ms/batch 41.86 | loss  3.62 | ppl    37.41\n",
            "| epoch  30 |   800/ 2981 batches | lr 0.03 | ms/batch 41.87 | loss  3.69 | ppl    40.12\n",
            "| epoch  30 |  1000/ 2981 batches | lr 0.03 | ms/batch 41.92 | loss  3.67 | ppl    39.21\n",
            "| epoch  30 |  1200/ 2981 batches | lr 0.03 | ms/batch 41.98 | loss  3.67 | ppl    39.43\n",
            "| epoch  30 |  1400/ 2981 batches | lr 0.03 | ms/batch 41.91 | loss  3.69 | ppl    40.07\n",
            "| epoch  30 |  1600/ 2981 batches | lr 0.03 | ms/batch 41.94 | loss  3.75 | ppl    42.54\n",
            "| epoch  30 |  1800/ 2981 batches | lr 0.03 | ms/batch 41.88 | loss  3.70 | ppl    40.27\n",
            "| epoch  30 |  2000/ 2981 batches | lr 0.03 | ms/batch 41.89 | loss  3.70 | ppl    40.44\n",
            "| epoch  30 |  2200/ 2981 batches | lr 0.03 | ms/batch 41.93 | loss  3.54 | ppl    34.39\n",
            "| epoch  30 |  2400/ 2981 batches | lr 0.03 | ms/batch 41.91 | loss  3.61 | ppl    37.04\n",
            "| epoch  30 |  2600/ 2981 batches | lr 0.03 | ms/batch 41.93 | loss  3.65 | ppl    38.51\n",
            "| epoch  30 |  2800/ 2981 batches | lr 0.03 | ms/batch 41.90 | loss  3.60 | ppl    36.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 129.03s | valid loss  5.19 | valid ppl   178.66\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whujgP2kvJzt",
        "outputId": "ad23bb12-c70c-4eba-ae9b-60cef680b01e"
      },
      "source": [
        "# save the model\n",
        "state = {\n",
        "    'model': model.state_dict(),\n",
        "    'epoch': epoch,\n",
        "    'val_loss': val_loss,\n",
        "    'bptt': bptt,\n",
        "    'ntokens': ntokens, \n",
        "    'emsize': emsize, \n",
        "    'nhead': nhead, \n",
        "    'nhid': nhid, \n",
        "    'nlayers': nlayers, \n",
        "    'dropout': dropout,\n",
        "    'logger': logger\n",
        "}\n",
        "torch.save(state, f'{CHECKPOINT_DIR}/{MODEL_NAME}_{epoch}.pth')\n",
        "print('-' * 89)\n",
        "print('| Model was saved |')\n",
        "print('-' * 89)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| Model was saved |\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaxNlkC53zsz",
        "outputId": "cbda4c62-8ae0-46d2-bff5-880574578fe6"
      },
      "source": [
        "# evalute best model on test dataset\n",
        "test_loss = evaluate(best_model, test_loader)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.11 | test ppl   165.11\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "yIAtaAd5DVXp",
        "outputId": "a642b23e-8840-4ce3-db1b-54fb718f8014"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15,8), dpi=200)\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# plot accuracy\n",
        "p1 = ax.plot(logger['epochs'], logger['train_loss'], linewidth=2, label='train\\nloss')\n",
        "p2 = ax.plot(logger['epochs'], logger['val_loss'], linewidth=2, label='validation\\nloss')\n",
        "ax.set_xticks(range(0, logger['epochs'][-1] + 1, 2))\n",
        "ax.set_xticklabels(range(0, logger['epochs'][-1] + 1, 2))\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss [%]')\n",
        "ax.set_title('Model Loss')\n",
        "ax.xaxis.grid()\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc8c9df4ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 3000x1600 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2oHS9VsSs-g"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 5  - Generate Sentences\n",
        "---\n",
        "Use the following function to generate 3 sentences of length 20, and print them. Do they make sense? (you can compare generated sentences over epochs, to see if some logic is gained during training)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYNNXCiSs-g"
      },
      "source": [
        "def generate(model, vocab, nwords=100, temp=1.0):\n",
        "    model.eval()\n",
        "    ntokens = len(vocab.stoi)\n",
        "    model_input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "    words = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(nwords):\n",
        "            output = model(model_input, None)\n",
        "            word_weights = output[-1].squeeze().div(temp).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "            model_input = torch.cat([model_input, word_tensor], 0)\n",
        "            word = vocab.itos[word_idx]\n",
        "            words.append(word)\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgcTYss8Ss-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01260b54-b0d9-4fb7-da61-adf804727199"
      },
      "source": [
        "\"\"\"\n",
        "Your code Here\n",
        "\"\"\"\n",
        "\n",
        "# load saved model\n",
        "state = torch.load(f'{CHECKPOINT_DIR}/{MODEL_NAME}_{30}.pth', map_location=device)\n",
        "best_model = TransformerModel(state['ntokens'], \n",
        "                              state['emsize'], \n",
        "                              state['nhead'], \n",
        "                              state['nhid'], \n",
        "                              state['nlayers'], \n",
        "                              state['dropout']).to(device)\n",
        "\n",
        "best_model.load_state_dict(state['model'])\n",
        "\n",
        "nsentences = 3 # Number of sentences to generate\n",
        "\n",
        "for i in range(nsentences):\n",
        "  sentence = generate(best_model, vocab, nwords=20)\n",
        "  print(f'Sentence {i}:')\n",
        "  print(\" \".join(sentence), '\\n')    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 0:\n",
            "to discover that the player knocks him inside facing the difficulty entirely . facing . after , degrom threw a \n",
            "\n",
            "Sentence 1:\n",
            "in 1913 , and 1914 . mosley attended the 1919 – 31 victory over moscow , the following day , \n",
            "\n",
            "Sentence 2:\n",
            "encountered with its fragile declaration of independence and cold war . jurchen forces had reached a peak strength of 140 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBy9tYqiv-rX"
      },
      "source": [
        "## Using Optuna for hyperparameters optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2r-FezUs-5T"
      },
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "epochs = 7\n",
        "ntokens = len(vocab.stoi)         # the size of vocabulary\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # get hyperparameters values with optuna\n",
        "    emsize = trial.suggest_categorical(\"emsize\", (216, 240))    # embbeding size\n",
        "    lr = trial.suggest_float(\"lr\", 1.5, 3)              # learning rate\n",
        "    nlayers = trial.suggest_int(\"nlayers\", 2, 4)        # number of layers\n",
        "    nhid = trial.suggest_int(\"nhid\", 200, 250)          # number of hidden units\n",
        "    nhead = trial.suggest_int(\"nhead\", 2, 4)            # number of Attention heads\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.01, 0.3) # dropout probability\n",
        "    step_decay = trial.suggest_int(\"step_decay\", 1, 4)  # Period of learning rate decay\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.1, 0.8)      # decay value for learning rate\n",
        "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"]) # optimizer \n",
        "\n",
        "\n",
        "    # Generate the model optimizer and scheduler\n",
        "    model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
        "    #optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_decay, gamma=gamma)\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    bptt=35\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        # train model\n",
        "        model.train() # Turn on the train mode\n",
        "        train_total_loss = 0.\n",
        "        start_time = time.time()\n",
        "        src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "        for batch, i in enumerate(range(0, train_loader.size(0) - 1, bptt)):\n",
        "            data, targets = get_batch(train_loader, i, bptt)\n",
        "            \n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "                \n",
        "            output = model(data, src_mask) # complete\n",
        "            loss = criterion(output.view(-1, ntokens), targets) # complete\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_total_loss += loss.item()\n",
        "            log_interval = 200\n",
        "            if batch % log_interval == 0 and batch > 0:\n",
        "                cur_loss = train_total_loss / log_interval\n",
        "                elapsed = time.time() - start_time\n",
        "                # print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                #       'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                #       'loss {:5.2f} '.format(\n",
        "                #         epoch, batch, len(train_loader) // bptt, scheduler.get_last_lr()[0],\n",
        "                #         elapsed * 1000 / log_interval,\n",
        "                #         cur_loss))\n",
        "                train_total_loss = 0\n",
        "                start_time = time.time()\n",
        "        \n",
        "        # evaluate the model\n",
        "        model.eval() # Turn on the evaluation mode\n",
        "        val_total_loss = 0.\n",
        "        src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, val_loader.size(0) - 1, bptt):\n",
        "                data, targets = get_batch(val_loader, i, bptt)\n",
        "                if data.size(0) != bptt:\n",
        "                    src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "                output = model(data, src_mask)\n",
        "                output_flat = output.view(-1, ntokens)\n",
        "                val_total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "        val_loss = val_total_loss / (len(val_loader) - 1)\n",
        "\n",
        "        # print('-' * 89)\n",
        "        # print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} '.format(epoch, (time.time() - epoch_start_time),\n",
        "        #                                 val_loss))\n",
        "        # print('-' * 89)\n",
        "\n",
        "        # report back to Optuna how far it is (epoch-wise) into the trial and how well it is doing (accuracy)\n",
        "        trial.report(val_loss, epoch)  \n",
        "\n",
        "        # then, Optuna can decide if the trial should be pruned\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            send_message('Trial-{} was pruned at epoch {}.\\nValidation loss: {}'.format(trial.number, epoch, val_loss))\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        # make a scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "    send_message('Trial-{} was done.\\nValidation loss: {}\\nParameters:\\n {}'.format(trial.number, val_loss, trial.params))\n",
        "    return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfKaUx0swVUa"
      },
      "source": [
        "### coarse optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vY_pVOvuwOQ",
        "outputId": "81731d02-85ef-43a3-ab04-f6bd7ad1ab6b"
      },
      "source": [
        "# now we can run the experiment\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "study = optuna.create_study(study_name=\"LM_Transformer\", direction=\"minimize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=40, timeout=42000)\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "# send a message to my phone when training is done\n",
        "send_message('The optuna optimization process of the LM_transformer model hypereparameters is done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-11 22:12:12,474]\u001b[0m A new study created in memory with name: LM_Transformer\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 22:23:09,316]\u001b[0m Trial 0 finished with value: 6.741337957703095 and parameters: {'lr': 0.007764457379688287, 'nlayers': 2, 'nhid': 236, 'nhead': 2, 'dropout': 0.03922642721135107, 'step_decay': 3, 'gamma': 0.36435682347597437, 'optimizer': 'Adam'}. Best is trial 0 with value: 6.741337957703095.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 22:33:34,214]\u001b[0m Trial 1 finished with value: 5.128520877396054 and parameters: {'lr': 2.387173203654453, 'nlayers': 4, 'nhid': 207, 'nhead': 4, 'dropout': 0.177540143242814, 'step_decay': 2, 'gamma': 0.9177936870923482, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 22:42:29,117]\u001b[0m Trial 2 finished with value: 6.112331306091684 and parameters: {'lr': 0.0243258695297438, 'nlayers': 2, 'nhid': 207, 'nhead': 3, 'dropout': 0.076328829331683, 'step_decay': 2, 'gamma': 0.6593860528855764, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 22:51:24,428]\u001b[0m Trial 3 finished with value: 5.339962076657719 and parameters: {'lr': 1.5765946604748022, 'nlayers': 2, 'nhid': 237, 'nhead': 2, 'dropout': 0.023127421068645362, 'step_decay': 5, 'gamma': 0.9157047834905634, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:00:21,291]\u001b[0m Trial 4 finished with value: 5.170516538064771 and parameters: {'lr': 0.5788349844316911, 'nlayers': 2, 'nhid': 246, 'nhead': 3, 'dropout': 0.1577129706547955, 'step_decay': 5, 'gamma': 0.8889972666217885, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:01:33,823]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:02:27,863]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:03:41,254]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:04:47,701]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:06:00,464]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:16:25,239]\u001b[0m Trial 10 finished with value: 5.222396758558595 and parameters: {'lr': 4.1140107860092545, 'nlayers': 4, 'nhid': 203, 'nhead': 4, 'dropout': 0.29310646195730417, 'step_decay': 1, 'gamma': 0.37452903170220364, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:17:28,462]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:18:31,540]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:28:56,136]\u001b[0m Trial 13 finished with value: 5.244832754331865 and parameters: {'lr': 3.308096201302672, 'nlayers': 4, 'nhid': 212, 'nhead': 4, 'dropout': 0.09860143683211935, 'step_decay': 4, 'gamma': 0.9493109865877933, 'optimizer': 'SGD'}. Best is trial 1 with value: 5.128520877396054.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:29:56,028]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:30:55,578]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:41:20,185]\u001b[0m Trial 16 finished with value: 5.032201233296627 and parameters: {'lr': 1.319620190858124, 'nlayers': 4, 'nhid': 200, 'nhead': 3, 'dropout': 0.16867628112573016, 'step_decay': 3, 'gamma': 0.46694718853081485, 'optimizer': 'SGD'}. Best is trial 16 with value: 5.032201233296627.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:51:44,846]\u001b[0m Trial 17 finished with value: 5.006040703925726 and parameters: {'lr': 1.809465610299424, 'nlayers': 4, 'nhid': 201, 'nhead': 4, 'dropout': 0.1793637541865675, 'step_decay': 3, 'gamma': 0.47795124902783, 'optimizer': 'SGD'}. Best is trial 17 with value: 5.006040703925726.\u001b[0m\n",
            "\u001b[32m[I 2021-06-11 23:52:47,892]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:03:12,478]\u001b[0m Trial 19 finished with value: 5.018577386251541 and parameters: {'lr': 1.2386085132605098, 'nlayers': 4, 'nhid': 202, 'nhead': 4, 'dropout': 0.11636103908512342, 'step_decay': 4, 'gamma': 0.4749247781717138, 'optimizer': 'SGD'}. Best is trial 17 with value: 5.006040703925726.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:06:20,390]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:07:23,474]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:08:26,518]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:11:34,336]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:12:37,381]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:13:40,503]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:14:40,092]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:25:04,847]\u001b[0m Trial 27 finished with value: 4.982590959261633 and parameters: {'lr': 2.2331678335436838, 'nlayers': 4, 'nhid': 210, 'nhead': 4, 'dropout': 0.1710362710131689, 'step_decay': 3, 'gamma': 0.3177143922830437, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:35:29,479]\u001b[0m Trial 28 finished with value: 4.997933280252673 and parameters: {'lr': 2.243832936030727, 'nlayers': 4, 'nhid': 209, 'nhead': 4, 'dropout': 0.11549028684318853, 'step_decay': 4, 'gamma': 0.33182558156587544, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:36:41,194]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:37:44,298]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:48:08,954]\u001b[0m Trial 31 finished with value: 5.017538515513962 and parameters: {'lr': 2.7034807749240035, 'nlayers': 4, 'nhid': 210, 'nhead': 4, 'dropout': 0.11541508267124655, 'step_decay': 4, 'gamma': 0.3543788131912465, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 00:58:33,550]\u001b[0m Trial 32 finished with value: 5.00938675324246 and parameters: {'lr': 2.6330509012991166, 'nlayers': 4, 'nhid': 210, 'nhead': 4, 'dropout': 0.1399011463835829, 'step_decay': 4, 'gamma': 0.3439718468129084, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 01:08:58,175]\u001b[0m Trial 33 finished with value: 4.989878662218146 and parameters: {'lr': 2.3067235739392733, 'nlayers': 4, 'nhid': 205, 'nhead': 4, 'dropout': 0.14478546238651746, 'step_decay': 2, 'gamma': 0.4109323815341397, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 01:10:01,368]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 01:20:26,051]\u001b[0m Trial 35 finished with value: 5.002594138498954 and parameters: {'lr': 1.9516672307077594, 'nlayers': 4, 'nhid': 207, 'nhead': 4, 'dropout': 0.08445076738638245, 'step_decay': 2, 'gamma': 0.4162068844013416, 'optimizer': 'SGD'}. Best is trial 27 with value: 4.982590959261633.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 01:21:29,162]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 01:31:53,850]\u001b[0m Trial 37 pruned. \u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09plaAnKwXik"
      },
      "source": [
        "### Fine optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kafHlBjgxV53",
        "outputId": "f4c23df5-e7ee-4ac8-fcd3-b75c8f92648e"
      },
      "source": [
        "# now we can run the experiment\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "study = optuna.create_study(study_name=\"LM_Transformer\", direction=\"minimize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=40, timeout=42000)\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "# send a message to my phone when training is done\n",
        "send_message('The optuna optimization process of the LM_transformer model hypereparameters is done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-12 16:18:54,343]\u001b[0m A new study created in memory with name: LM_Transformer\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 16:33:30,591]\u001b[0m Trial 0 finished with value: 5.160392798653464 and parameters: {'emsize': 216, 'lr': 2.12165323781079, 'nlayers': 3, 'nhid': 248, 'nhead': 4, 'dropout': 0.2915723945731309, 'step_decay': 3, 'gamma': 0.6416670741578635}. Best is trial 0 with value: 5.160392798653464.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 16:49:22,996]\u001b[0m Trial 1 finished with value: 5.142858905360298 and parameters: {'emsize': 216, 'lr': 2.637413636581579, 'nlayers': 4, 'nhid': 208, 'nhead': 4, 'dropout': 0.20763145610103886, 'step_decay': 4, 'gamma': 0.71538465981417}. Best is trial 1 with value: 5.142858905360298.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:03:27,311]\u001b[0m Trial 2 finished with value: 5.097587898910521 and parameters: {'emsize': 240, 'lr': 2.387677644711462, 'nlayers': 2, 'nhid': 224, 'nhead': 4, 'dropout': 0.13071221255279464, 'step_decay': 1, 'gamma': 0.48350324497600083}. Best is trial 2 with value: 5.097587898910521.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:17:02,189]\u001b[0m Trial 3 finished with value: 5.056086655376571 and parameters: {'emsize': 216, 'lr': 2.269584192805545, 'nlayers': 2, 'nhid': 212, 'nhead': 4, 'dropout': 0.18428227745382458, 'step_decay': 3, 'gamma': 0.12413634025588427}. Best is trial 3 with value: 5.056086655376571.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:31:34,474]\u001b[0m Trial 4 finished with value: 5.097297099854842 and parameters: {'emsize': 216, 'lr': 2.549911034301068, 'nlayers': 3, 'nhid': 201, 'nhead': 4, 'dropout': 0.17933945966567108, 'step_decay': 4, 'gamma': 0.3947811906548898}. Best is trial 3 with value: 5.056086655376571.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:33:31,790]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:35:53,122]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 17:52:16,374]\u001b[0m Trial 7 finished with value: 5.040194518539682 and parameters: {'emsize': 240, 'lr': 2.3207393953966555, 'nlayers': 4, 'nhid': 223, 'nhead': 4, 'dropout': 0.17838446802589364, 'step_decay': 2, 'gamma': 0.4743508121114588}. Best is trial 7 with value: 5.040194518539682.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 18:08:09,524]\u001b[0m Trial 8 finished with value: 5.073691824261358 and parameters: {'emsize': 216, 'lr': 2.287093387840854, 'nlayers': 4, 'nhid': 244, 'nhead': 3, 'dropout': 0.12737238602582715, 'step_decay': 2, 'gamma': 0.7935650311509738}. Best is trial 7 with value: 5.040194518539682.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 18:13:59,746]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 18:23:21,056]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 18:38:28,114]\u001b[0m Trial 11 finished with value: 4.999077273145259 and parameters: {'emsize': 240, 'lr': 2.9532273669338855, 'nlayers': 3, 'nhid': 214, 'nhead': 2, 'dropout': 0.0679924404226665, 'step_decay': 3, 'gamma': 0.11387398408524015}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 18:53:33,265]\u001b[0m Trial 12 finished with value: 5.050836703927486 and parameters: {'emsize': 240, 'lr': 2.9622135423592324, 'nlayers': 3, 'nhid': 214, 'nhead': 2, 'dropout': 0.056899715509401996, 'step_decay': 3, 'gamma': 0.2997542639883056}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 19:02:10,451]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 19:11:32,605]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 19:13:44,183]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 19:30:16,077]\u001b[0m Trial 16 finished with value: 5.038435943799724 and parameters: {'emsize': 240, 'lr': 1.8987226073837598, 'nlayers': 4, 'nhid': 218, 'nhead': 3, 'dropout': 0.014873939951602883, 'step_decay': 2, 'gamma': 0.1861770576322967}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 19:45:27,423]\u001b[0m Trial 17 finished with value: 5.043236000679738 and parameters: {'emsize': 240, 'lr': 1.8061677484693233, 'nlayers': 3, 'nhid': 207, 'nhead': 3, 'dropout': 0.011936434833965514, 'step_decay': 3, 'gamma': 0.19002183514091936}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:01:55,131]\u001b[0m Trial 18 finished with value: 5.0459569167443785 and parameters: {'emsize': 240, 'lr': 1.9290057349096748, 'nlayers': 4, 'nhid': 218, 'nhead': 2, 'dropout': 0.044769626229443873, 'step_decay': 2, 'gamma': 0.11073534413029781}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:17:07,464]\u001b[0m Trial 19 finished with value: 5.035496179371364 and parameters: {'emsize': 240, 'lr': 1.5138890839453072, 'nlayers': 3, 'nhid': 206, 'nhead': 3, 'dropout': 0.037402275487701496, 'step_decay': 3, 'gamma': 0.20473743771164046}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:19:18,228]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:34:31,839]\u001b[0m Trial 21 finished with value: 5.028505911057206 and parameters: {'emsize': 240, 'lr': 1.6829020967416268, 'nlayers': 3, 'nhid': 215, 'nhead': 3, 'dropout': 0.037325664660693814, 'step_decay': 3, 'gamma': 0.19414206102443016}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:49:44,161]\u001b[0m Trial 22 finished with value: 5.0269072738043095 and parameters: {'emsize': 240, 'lr': 1.680555834536628, 'nlayers': 3, 'nhid': 212, 'nhead': 3, 'dropout': 0.046592700934888556, 'step_decay': 3, 'gamma': 0.19025144715133657}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:51:55,335]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 20:58:25,640]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:00:36,689]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:04:39,987]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:15:30,063]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:22:01,743]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:24:12,830]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:32:19,438]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:34:29,730]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:38:49,430]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 21:53:53,144]\u001b[0m Trial 33 finished with value: 5.0066618720890785 and parameters: {'emsize': 240, 'lr': 2.490729324517335, 'nlayers': 3, 'nhid': 211, 'nhead': 3, 'dropout': 0.08473754521178828, 'step_decay': 3, 'gamma': 0.21100526731594993}. Best is trial 11 with value: 4.999077273145259.\u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:00:20,620]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:02:30,414]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:08:31,127]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:12:39,839]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:16:58,491]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-06-12 22:21:16,423]\u001b[0m Trial 39 pruned. \u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  40\n",
            "  Number of pruned trials:  24\n",
            "  Number of complete trials:  16\n",
            "Best trial:\n",
            "  Value:  4.999077273145259\n",
            "  Params: \n",
            "    emsize: 240\n",
            "    lr: 2.9532273669338855\n",
            "    nlayers: 3\n",
            "    nhid: 214\n",
            "    nhead: 2\n",
            "    dropout: 0.0679924404226665\n",
            "    step_decay: 3\n",
            "    gamma: 0.11387398408524015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnlTSYoSCocX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c88b093e-f078-40fc-9636-cff99d2477e6"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"20d95a99-5aa0-4628-9dbe-ee2901f96868\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"20d95a99-5aa0-4628-9dbe-ee2901f96868\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '20d95a99-5aa0-4628-9dbe-ee2901f96868',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"nlayers (IntUniformDistribution): 0.010108501657829828<extra></extra>\", \"step_decay (IntUniformDistribution): 0.02331428240902003<extra></extra>\", \"emsize (CategoricalDistribution): 0.03770448323143016<extra></extra>\", \"nhead (IntUniformDistribution): 0.06056110927029623<extra></extra>\", \"lr (UniformDistribution): 0.06444757063551623<extra></extra>\", \"nhid (IntUniformDistribution): 0.07938303987090355<extra></extra>\", \"dropout (UniformDistribution): 0.2782685979283164<extra></extra>\", \"gamma (UniformDistribution): 0.4462124149966878<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.010108501657829828\", \"0.02331428240902003\", \"0.03770448323143016\", \"0.06056110927029623\", \"0.06444757063551623\", \"0.07938303987090355\", \"0.2782685979283164\", \"0.4462124149966878\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.010108501657829828, 0.02331428240902003, 0.03770448323143016, 0.06056110927029623, 0.06444757063551623, 0.07938303987090355, 0.2782685979283164, 0.4462124149966878], \"y\": [\"nlayers\", \"step_decay\", \"emsize\", \"nhead\", \"lr\", \"nhid\", \"dropout\", \"gamma\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('20d95a99-5aa0-4628-9dbe-ee2901f96868');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5J0WZFLksFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "26c31d1b-85d3-44b2-9c0f-f14e1818f76c"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"lr\", \"dropout\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"dcbd9d51-e978-494b-8f21-88241b7035e1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"dcbd9d51-e978-494b-8f21-88241b7035e1\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'dcbd9d51-e978-494b-8f21-88241b7035e1',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [-0.0020453631529927553, 0.011936434833965514, 0.014873939951602883, 0.037325664660693814, 0.037402275487701496, 0.044769626229443873, 0.046592700934888556, 0.056899715509401996, 0.0679924404226665, 0.08473754521178828, 0.12737238602582715, 0.13071221255279464, 0.17838446802589364, 0.17933945966567108, 0.18428227745382458, 0.20763145610103886, 0.2915723945731309, 0.30555419256008914], \"y\": [1.441472861024611, 1.5138890839453072, 1.680555834536628, 1.6829020967416268, 1.8061677484693233, 1.8987226073837598, 1.9290057349096748, 2.12165323781079, 2.269584192805545, 2.287093387840854, 2.3207393953966555, 2.387677644711462, 2.490729324517335, 2.549911034301068, 2.637413636581579, 2.9532273669338855, 2.9622135423592324, 3.0346297652799286], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 5.035496179371364, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 5.0269072738043095, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 5.038435943799724, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 5.0459569167443785, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.160392798653464, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.056086655376571, null, null, null], [null, null, null, null, null, null, null, null, null, null, 5.073691824261358, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null], [null, null, null, null, null, null, null, null, 4.999077273145259, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 5.050836703927486, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.2915723945731309, 0.20763145610103886, 0.13071221255279464, 0.18428227745382458, 0.17933945966567108, 0.17838446802589364, 0.12737238602582715, 0.0679924404226665, 0.056899715509401996, 0.014873939951602883, 0.011936434833965514, 0.044769626229443873, 0.037402275487701496, 0.037325664660693814, 0.046592700934888556, 0.08473754521178828], \"y\": [2.12165323781079, 2.637413636581579, 2.387677644711462, 2.269584192805545, 2.549911034301068, 2.3207393953966555, 2.287093387840854, 2.9532273669338855, 2.9622135423592324, 1.8987226073837598, 1.8061677484693233, 1.9290057349096748, 1.5138890839453072, 1.6829020967416268, 1.680555834536628, 2.490729324517335]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [-0.0020453631529927553, 0.30555419256008914], \"title\": {\"text\": \"dropout\"}}, \"yaxis\": {\"range\": [1.441472861024611, 3.0346297652799286], \"title\": {\"text\": \"lr\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dcbd9d51-e978-494b-8f21-88241b7035e1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2H1iI825_qGr",
        "outputId": "a5240069-4cc1-4d58-e95f-a205aa8f436f"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"lr\", \"nhid\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1c98bb07-a99f-4bed-b5b8-b102ef7b9f89\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1c98bb07-a99f-4bed-b5b8-b102ef7b9f89\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1c98bb07-a99f-4bed-b5b8-b102ef7b9f89',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [1.441472861024611, 1.5138890839453072, 1.680555834536628, 1.6829020967416268, 1.8061677484693233, 1.8987226073837598, 1.9290057349096748, 2.12165323781079, 2.269584192805545, 2.287093387840854, 2.3207393953966555, 2.387677644711462, 2.490729324517335, 2.549911034301068, 2.637413636581579, 2.9532273669338855, 2.9622135423592324, 3.0346297652799286], \"y\": [198.65, 201, 206, 207, 208, 211, 212, 214, 215, 218, 223, 224, 244, 248, 250.35], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null], [null, 5.035496179371364, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null], [null, null, 5.0269072738043095, null, null, null, null, null, 5.056086655376571, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 4.999077273145259, 5.050836703927486, null], [null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 5.038435943799724, 5.0459569167443785, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 5.073691824261358, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 5.160392798653464, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [2.12165323781079, 2.637413636581579, 2.387677644711462, 2.269584192805545, 2.549911034301068, 2.3207393953966555, 2.287093387840854, 2.9532273669338855, 2.9622135423592324, 1.8987226073837598, 1.8061677484693233, 1.9290057349096748, 1.5138890839453072, 1.6829020967416268, 1.680555834536628, 2.490729324517335], \"y\": [248, 208, 224, 212, 201, 223, 244, 214, 214, 218, 207, 218, 206, 215, 212, 211]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [1.441472861024611, 3.0346297652799286], \"title\": {\"text\": \"lr\"}}, \"yaxis\": {\"range\": [198.65, 250.35], \"title\": {\"text\": \"nhid\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1c98bb07-a99f-4bed-b5b8-b102ef7b9f89');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PCQPtPJr_vmj",
        "outputId": "a6e2df04-b10b-41de-984b-acbf232365b1"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"dropout\", \"nhid\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"19c66337-ff3b-4478-bd8d-ac9fb1c2b996\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"19c66337-ff3b-4478-bd8d-ac9fb1c2b996\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '19c66337-ff3b-4478-bd8d-ac9fb1c2b996',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [-0.0020453631529927553, 0.011936434833965514, 0.014873939951602883, 0.037325664660693814, 0.037402275487701496, 0.044769626229443873, 0.046592700934888556, 0.056899715509401996, 0.0679924404226665, 0.08473754521178828, 0.12737238602582715, 0.13071221255279464, 0.17838446802589364, 0.17933945966567108, 0.18428227745382458, 0.20763145610103886, 0.2915723945731309, 0.30555419256008914], \"y\": [198.65, 201, 206, 207, 208, 211, 212, 214, 215, 218, 223, 224, 244, 248, 250.35], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null], [null, null, null, null, 5.035496179371364, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null], [null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 5.0269072738043095, null, null, null, null, null, null, null, 5.056086655376571, null, null, null], [null, null, null, null, null, null, null, 5.050836703927486, 4.999077273145259, null, null, null, null, null, null, null, null, null], [null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, 5.038435943799724, null, null, 5.0459569167443785, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 5.073691824261358, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.160392798653464, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.2915723945731309, 0.20763145610103886, 0.13071221255279464, 0.18428227745382458, 0.17933945966567108, 0.17838446802589364, 0.12737238602582715, 0.0679924404226665, 0.056899715509401996, 0.014873939951602883, 0.011936434833965514, 0.044769626229443873, 0.037402275487701496, 0.037325664660693814, 0.046592700934888556, 0.08473754521178828], \"y\": [248, 208, 224, 212, 201, 223, 244, 214, 214, 218, 207, 218, 206, 215, 212, 211]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [-0.0020453631529927553, 0.30555419256008914], \"title\": {\"text\": \"dropout\"}}, \"yaxis\": {\"range\": [198.65, 250.35], \"title\": {\"text\": \"nhid\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('19c66337-ff3b-4478-bd8d-ac9fb1c2b996');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "nrxF2DP7_vq5",
        "outputId": "aa8db528-b2cf-411c-910f-0f1ea94d42c7"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"lr\", \"gamma\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"f137aa28-ca0f-4fae-b2a5-95fbcc5c8fe2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"f137aa28-ca0f-4fae-b2a5-95fbcc5c8fe2\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'f137aa28-ca0f-4fae-b2a5-95fbcc5c8fe2',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [0.07659385977926401, 0.11073534413029781, 0.11387398408524015, 0.12413634025588427, 0.1861770576322967, 0.19002183514091936, 0.19025144715133657, 0.19414206102443016, 0.20473743771164046, 0.21100526731594993, 0.2997542639883056, 0.3947811906548898, 0.4743508121114588, 0.48350324497600083, 0.6416670741578635, 0.71538465981417, 0.7935650311509738, 0.8277065155020076], \"y\": [1.441472861024611, 1.5138890839453072, 1.680555834536628, 1.6829020967416268, 1.8061677484693233, 1.8987226073837598, 1.9290057349096748, 2.12165323781079, 2.269584192805545, 2.287093387840854, 2.3207393953966555, 2.387677644711462, 2.490729324517335, 2.549911034301068, 2.637413636581579, 2.9532273669338855, 2.9622135423592324, 3.0346297652799286], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 5.035496179371364, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 5.0269072738043095, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 5.038435943799724, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 5.0459569167443785, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.160392798653464, null, null, null], [null, null, null, 5.056086655376571, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.073691824261358, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null], [null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null], [null, null, 4.999077273145259, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, 5.050836703927486, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.6416670741578635, 0.71538465981417, 0.48350324497600083, 0.12413634025588427, 0.3947811906548898, 0.4743508121114588, 0.7935650311509738, 0.11387398408524015, 0.2997542639883056, 0.1861770576322967, 0.19002183514091936, 0.11073534413029781, 0.20473743771164046, 0.19414206102443016, 0.19025144715133657, 0.21100526731594993], \"y\": [2.12165323781079, 2.637413636581579, 2.387677644711462, 2.269584192805545, 2.549911034301068, 2.3207393953966555, 2.287093387840854, 2.9532273669338855, 2.9622135423592324, 1.8987226073837598, 1.8061677484693233, 1.9290057349096748, 1.5138890839453072, 1.6829020967416268, 1.680555834536628, 2.490729324517335]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [0.07659385977926401, 0.8277065155020076], \"title\": {\"text\": \"gamma\"}}, \"yaxis\": {\"range\": [1.441472861024611, 3.0346297652799286], \"title\": {\"text\": \"lr\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f137aa28-ca0f-4fae-b2a5-95fbcc5c8fe2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4EZH3Hcg_vtl",
        "outputId": "456a163e-cd07-4ce6-dd23-1e95b504c127"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"gamma\", \"dropout\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4ef598c5-4142-44aa-903a-7e2e043d02ea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4ef598c5-4142-44aa-903a-7e2e043d02ea\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4ef598c5-4142-44aa-903a-7e2e043d02ea',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [-0.0020453631529927553, 0.011936434833965514, 0.014873939951602883, 0.037325664660693814, 0.037402275487701496, 0.044769626229443873, 0.046592700934888556, 0.056899715509401996, 0.0679924404226665, 0.08473754521178828, 0.12737238602582715, 0.13071221255279464, 0.17838446802589364, 0.17933945966567108, 0.18428227745382458, 0.20763145610103886, 0.2915723945731309, 0.30555419256008914], \"y\": [0.07659385977926401, 0.11073534413029781, 0.11387398408524015, 0.12413634025588427, 0.1861770576322967, 0.19002183514091936, 0.19025144715133657, 0.19414206102443016, 0.20473743771164046, 0.21100526731594993, 0.2997542639883056, 0.3947811906548898, 0.4743508121114588, 0.48350324497600083, 0.6416670741578635, 0.71538465981417, 0.7935650311509738, 0.8277065155020076], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 5.0459569167443785, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 4.999077273145259, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.056086655376571, null, null, null], [null, null, 5.038435943799724, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, 5.0269072738043095, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, 5.035496179371364, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 5.050836703927486, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.160392798653464, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null], [null, null, null, null, null, null, null, null, null, null, 5.073691824261358, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.2915723945731309, 0.20763145610103886, 0.13071221255279464, 0.18428227745382458, 0.17933945966567108, 0.17838446802589364, 0.12737238602582715, 0.0679924404226665, 0.056899715509401996, 0.014873939951602883, 0.011936434833965514, 0.044769626229443873, 0.037402275487701496, 0.037325664660693814, 0.046592700934888556, 0.08473754521178828], \"y\": [0.6416670741578635, 0.71538465981417, 0.48350324497600083, 0.12413634025588427, 0.3947811906548898, 0.4743508121114588, 0.7935650311509738, 0.11387398408524015, 0.2997542639883056, 0.1861770576322967, 0.19002183514091936, 0.11073534413029781, 0.20473743771164046, 0.19414206102443016, 0.19025144715133657, 0.21100526731594993]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [-0.0020453631529927553, 0.30555419256008914], \"title\": {\"text\": \"dropout\"}}, \"yaxis\": {\"range\": [0.07659385977926401, 0.8277065155020076], \"title\": {\"text\": \"gamma\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4ef598c5-4142-44aa-903a-7e2e043d02ea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "erM_MSY2_-xt",
        "outputId": "18f2ffb4-90e8-469a-a60a-4adb9a4adebd"
      },
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"gamma\", \"nhid\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"65ef1d53-e4ca-4b98-91a9-f5ba18ecb600\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"65ef1d53-e4ca-4b98-91a9-f5ba18ecb600\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '65ef1d53-e4ca-4b98-91a9-f5ba18ecb600',\n",
              "                        [{\"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0, \"rgb(5,10,172)\"], [0.35, \"rgb(40,60,190)\"], [0.5, \"rgb(70,100,245)\"], [0.6, \"rgb(90,120,245)\"], [0.7, \"rgb(106,137,247)\"], [1, \"rgb(220,220,220)\"]], \"connectgaps\": true, \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"none\", \"line\": {\"smoothing\": 1.3}, \"reversescale\": true, \"type\": \"contour\", \"x\": [0.07659385977926401, 0.11073534413029781, 0.11387398408524015, 0.12413634025588427, 0.1861770576322967, 0.19002183514091936, 0.19025144715133657, 0.19414206102443016, 0.20473743771164046, 0.21100526731594993, 0.2997542639883056, 0.3947811906548898, 0.4743508121114588, 0.48350324497600083, 0.6416670741578635, 0.71538465981417, 0.7935650311509738, 0.8277065155020076], \"y\": [198.65, 201, 206, 207, 208, 211, 212, 214, 215, 218, 223, 224, 244, 248, 250.35], \"z\": [[null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, 5.097297099854842, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, 5.035496179371364, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, 5.043236000679738, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.142858905360298, null, null], [null, null, null, null, null, null, null, null, null, 5.0066618720890785, null, null, null, null, null, null, null, null], [null, null, null, 5.056086655376571, null, null, 5.0269072738043095, null, null, null, null, null, null, null, null, null, null, null], [null, null, 4.999077273145259, null, null, null, null, null, null, null, 5.050836703927486, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, 5.028505911057206, null, null, null, null, null, null, null, null, null, null], [null, 5.0459569167443785, null, null, 5.038435943799724, null, null, null, null, null, null, null, null, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, 5.040194518539682, null, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, 5.097587898910521, null, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.073691824261358, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5.160392798653464, null, null, null], [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null]]}, {\"marker\": {\"color\": \"black\", \"line\": {\"color\": \"Grey\", \"width\": 0.5}}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.6416670741578635, 0.71538465981417, 0.48350324497600083, 0.12413634025588427, 0.3947811906548898, 0.4743508121114588, 0.7935650311509738, 0.11387398408524015, 0.2997542639883056, 0.1861770576322967, 0.19002183514091936, 0.11073534413029781, 0.20473743771164046, 0.19414206102443016, 0.19025144715133657, 0.21100526731594993], \"y\": [248, 208, 224, 212, 201, 223, 244, 214, 214, 218, 207, 218, 206, 215, 212, 211]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Contour Plot\"}, \"xaxis\": {\"range\": [0.07659385977926401, 0.8277065155020076], \"title\": {\"text\": \"gamma\"}}, \"yaxis\": {\"range\": [198.65, 250.35], \"title\": {\"text\": \"nhid\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('65ef1d53-e4ca-4b98-91a9-f5ba18ecb600');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkBzqLP7Ss-g"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    }
  ]
}